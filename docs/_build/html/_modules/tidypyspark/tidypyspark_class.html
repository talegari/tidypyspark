<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>tidypyspark.tidypyspark_class &mdash; tidypyspark  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            tidypyspark
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autoapi/index.html">API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">tidypyspark</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">tidypyspark.tidypyspark_class</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for tidypyspark.tidypyspark_class</h1><div class="highlight"><pre>
<span></span><span class="c1"># ----------------------------------------------------------------------------</span>
<span class="c1"># This file is a part of tidypyspark python package</span>
<span class="c1"># Find the dev version here: https://github.com/talegari/tidypyspark</span>
<span class="c1"># ---------------------------------------------------------------------</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">pyspark</span>
<span class="kn">import</span> <span class="nn">pyspark.sql.functions</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.window</span> <span class="kn">import</span> <span class="n">Window</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">collections_extended</span> <span class="kn">import</span> <span class="n">setlist</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">tidypyspark.accessor_class</span> <span class="kn">import</span> <span class="n">register_dataframe_accessor</span>
<span class="kn">from</span> <span class="nn">tidypyspark._unexported_utils</span> <span class="kn">import</span> <span class="p">(</span>
                              <span class="n">_is_kwargable</span><span class="p">,</span>
                              <span class="n">_is_valid_colname</span><span class="p">,</span>
                              <span class="n">_is_string_or_string_list</span><span class="p">,</span>
                              <span class="n">_enlist</span><span class="p">,</span>
                              <span class="n">_get_unique_names</span><span class="p">,</span>
                              <span class="n">_is_unique_list</span><span class="p">,</span>
                              <span class="n">_generate_new_string</span><span class="p">,</span>
                              <span class="n">_is_nested</span><span class="p">,</span>
                              <span class="n">_flatten_strings</span><span class="p">,</span>
                              <span class="n">_nested_is_unique</span><span class="p">,</span>
                              <span class="n">_get_compatible_datatypes_of_python_and_spark</span>
                            <span class="p">)</span>

<span class="c1"># tidypyspark ----</span>
<div class="viewcode-block" id="acc_on_pyspark"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark">[docs]</a><span class="nd">@register_dataframe_accessor</span><span class="p">(</span><span class="s1">&#39;ts&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">acc_on_pyspark</span><span class="p">():</span>
<span class="w">  </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">  </span>
<span class="sd">  &#39;&#39;&#39;</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    
    <span class="c1"># assign __data attribute</span>
    <span class="n">colnames</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><span class="n">_is_valid_colname</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">colnames</span><span class="p">]),</span>\
      <span class="s2">&quot;column names should not start with underscore&quot;</span>
    <span class="k">assert</span> <span class="n">_is_unique_list</span><span class="p">(</span><span class="n">colnames</span><span class="p">),</span>\
      <span class="s2">&quot;column names should be unique&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">data</span>
  
  <span class="c1"># attributes -------------------------------------------------------------</span>
  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">nrow</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    nrow</span>
<span class="sd">    get munber of rows</span>
<span class="sd">    </span>
<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Just a placeholder to inform user to use count() method</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    None</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Please run: `df.ts.count()` to get the number of rows&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">None</span>
  
  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">ncol</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    ncol</span>
<span class="sd">    get number of columns</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    (Integer) Number of columns</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
  
  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">colnames</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    dim</span>
<span class="sd">    get column names</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list with column names as strings</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
  
  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    shape</span>
<span class="sd">    get shape</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple of number of rows and number of columns</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nrow</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ncol</span><span class="p">)</span>
  
  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">dim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    dim</span>
<span class="sd">    get shape</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple of number of rows and number of columns</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nrow</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ncol</span><span class="p">)</span>
  
  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">types</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    types</span>
<span class="sd">    identify column types as strings</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict with column names as keys, types as a values</span>
<span class="sd">    type is a string.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">types</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">dataType</span><span class="o">.</span><span class="n">typeName</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">fields</span><span class="p">]</span>
    <span class="n">res</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">types</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span>

  <span class="c1"># cleaners --------------------------------------------------------------</span>
<div class="viewcode-block" id="acc_on_pyspark._validate_by"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._validate_by">[docs]</a>  <span class="k">def</span> <span class="nf">_validate_by</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">by</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    _validate_by</span>
<span class="sd">    validates &#39;by&#39; and returns a list of column names</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    by : string, list of strings</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list of column names</span>
<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="n">cns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span>
    <span class="n">by</span> <span class="o">=</span> <span class="n">_enlist</span><span class="p">(</span><span class="n">by</span><span class="p">)</span>
    
    <span class="k">assert</span> <span class="n">_is_string_or_string_list</span><span class="p">(</span><span class="n">by</span><span class="p">),</span>\
      <span class="s2">&quot;&#39;by&#39; should be a string or list of strings&quot;</span>
    <span class="k">assert</span> <span class="n">_is_unique_list</span><span class="p">(</span><span class="n">by</span><span class="p">),</span>\
      <span class="s2">&quot;&#39;by&#39; should be a list of unique strings&quot;</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">by</span><span class="p">)</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">cns</span><span class="p">),</span>\
      <span class="s2">&quot;&#39;by&#39; should be a list of valid column names&quot;</span>
    
    <span class="k">return</span> <span class="n">by</span></div>

<div class="viewcode-block" id="acc_on_pyspark._validate_order_by"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._validate_order_by">[docs]</a>  <span class="k">def</span> <span class="nf">_validate_order_by</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">order_by</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    _validate_order_by</span>
<span class="sd">    validates and returns a list of &#39;column&#39; objects</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    order_by : string or tuple or list of tuples</span>
<span class="sd">        Order by specification, see Notes</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list of &#39;column&#39; objects</span>
<span class="sd">    </span>
<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    1. A &#39;column&#39; object is an instance of &#39;pyspark.sql.Column&#39;.</span>
<span class="sd">    2. Prototype of return objects:</span>
<span class="sd">      - [&quot;col_a&quot;, (&quot;col_b&quot;, &quot;desc&quot;)] --&gt; [col(&#39;col_a&#39;), col(&#39;col_b&#39;).desc()]</span>
<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="n">cns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span>
    
    <span class="c1"># convert string to list, tuple to list</span>
    <span class="n">order_by</span> <span class="o">=</span> <span class="n">_enlist</span><span class="p">(</span><span class="n">order_by</span><span class="p">)</span>
    
    <span class="c1"># handle order_by</span>
    <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">order_by</span><span class="p">):</span>           
      
      <span class="c1"># case 1: tuple</span>
      <span class="c1"># prototypes:</span>
      <span class="c1"># (&#39;col_a&#39;, &#39;asc&#39;)</span>
      <span class="c1"># (F.col(&#39;col_a&#39;), &#39;desc&#39;)</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span>\
          <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Input tuple should have length 2. &#39;</span>
           <span class="sa">f</span><span class="s1">&#39;Input: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s1">&#39;</span>
           <span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">),</span>\
          <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;First element of the input tuple should be a string. &#39;</span>
           <span class="sa">f</span><span class="s1">&#39;Input: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s1">&#39;</span>
           <span class="p">)</span>
        <span class="n">allowed</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;asc&#39;</span><span class="p">,</span> <span class="s1">&#39;desc&#39;</span><span class="p">,</span> <span class="s1">&#39;asc_null_first&#39;</span><span class="p">,</span> <span class="s1">&#39;desc_nulls_first&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">allowed</span><span class="p">:</span>
          <span class="k">raise</span> <span class="ne">Exception</span><span class="p">((</span><span class="sa">f</span><span class="s1">&#39;Second element of the input tuple should &#39;</span>
                           <span class="sa">f</span><span class="s1">&#39;one among: </span><span class="si">{</span><span class="n">allowed</span><span class="si">}</span><span class="s1">. &#39;</span>
                           <span class="sa">f</span><span class="s1">&#39;Input: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s1">&#39;</span>
                           <span class="p">))</span>
        
        <span class="k">assert</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="n">cns</span><span class="p">,</span>\
          <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;String input to &#39;order_by&#39; should be a valid column name. &quot;</span>
           <span class="sa">f</span><span class="s2">&quot;Input: </span><span class="si">{</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
           <span class="p">)</span>
          
        <span class="k">if</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;asc&#39;</span><span class="p">:</span>
          <span class="n">order_by</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">asc_nulls_last</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;asc_nulls_first&#39;</span><span class="p">:</span>
          <span class="n">order_by</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">asc_nulls_first</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;desc&#39;</span><span class="p">:</span>
          <span class="n">order_by</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">desc_nulls_last</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">order_by</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">desc_nulls_first</span><span class="p">()</span>
      
      <span class="c1"># case 2: string</span>
      <span class="c1"># prototypes:</span>
      <span class="c1"># &#39;col_a&#39;</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">cns</span><span class="p">,</span>\
          <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;String input to &#39;order_by&#39; should be a valid column name. &quot;</span>
           <span class="sa">f</span><span class="s1">&#39;Input: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s1">&#39;</span>
           <span class="p">)</span>
        <span class="n">order_by</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">asc_nulls_last</span><span class="p">()</span>
      
      <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">((</span><span class="s2">&quot;An element of &#39;order_by&#39; should be a tuple or &quot;</span>
                         <span class="s2">&quot;a string&quot;</span><span class="p">))</span>
      
    <span class="k">return</span> <span class="n">order_by</span></div>
      
<div class="viewcode-block" id="acc_on_pyspark._validate_column_names"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._validate_column_names">[docs]</a>  <span class="k">def</span> <span class="nf">_validate_column_names</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column_names</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    _validate_column_names</span>
<span class="sd">    validates and returns column names</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    column_names : string or list of strings</span>
<span class="sd">      columns names to be validated</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list of column names</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">cns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span>
    <span class="n">column_names</span> <span class="o">=</span> <span class="n">_enlist</span><span class="p">(</span><span class="n">column_names</span><span class="p">)</span>
    
    <span class="k">assert</span> <span class="n">_is_string_or_string_list</span><span class="p">(</span><span class="n">column_names</span><span class="p">),</span>\
      <span class="s2">&quot;&#39;column_names&#39; should be a string or list of strings&quot;</span>
    <span class="k">assert</span> <span class="n">_is_unique_list</span><span class="p">(</span><span class="n">column_names</span><span class="p">),</span>\
      <span class="s2">&quot;&#39;column_names&#39; should be a list of unique strings&quot;</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">column_names</span><span class="p">)</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">cns</span><span class="p">),</span>\
      <span class="s2">&quot;&#39;column_names&#39; should be a list of valid column names&quot;</span>
    
    <span class="k">return</span> <span class="n">column_names</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark._extract_order_by_cols"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._extract_order_by_cols">[docs]</a>  <span class="k">def</span> <span class="nf">_extract_order_by_cols</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">order_by</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    _extract_order_by_cols</span>
<span class="sd">    Extract column names from order_by specification</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    order_by : string or tuple or list of tuples</span>
<span class="sd">        Order by specification</span>
<span class="sd">        ex: [&quot;col_a&quot;, (&quot;col_b&quot;, &quot;desc&quot;)]</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list of column names in order_by</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">cns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span>
    
    <span class="c1"># convert string to list, tuple to list</span>
    <span class="n">order_by</span> <span class="o">=</span> <span class="n">_enlist</span><span class="p">(</span><span class="n">order_by</span><span class="p">)</span>
    
    <span class="n">out</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">order_by</span><span class="p">)</span>
    <span class="c1"># handle order_by</span>
    <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">order_by</span><span class="p">):</span>           
      
      <span class="c1"># case 1: tuple</span>
      <span class="c1"># prototypes:</span>
      <span class="c1"># (&#39;col_a&#39;, &#39;asc&#39;)</span>
      <span class="c1"># (F.col(&#39;col_a&#39;), &#39;desc&#39;)</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span>\
          <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Input tuple should have length 2. &#39;</span>
           <span class="sa">f</span><span class="s1">&#39;Input: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s1">&#39;</span>
           <span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">),</span>\
          <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;First element of the input tuple should be a string. &#39;</span>
           <span class="sa">f</span><span class="s1">&#39;Input: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s1">&#39;</span>
           <span class="p">)</span>
        <span class="n">allowed</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;asc&#39;</span><span class="p">,</span> <span class="s1">&#39;desc&#39;</span><span class="p">,</span> <span class="s1">&#39;asc_null_first&#39;</span><span class="p">,</span> <span class="s1">&#39;desc_nulls_first&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">allowed</span><span class="p">:</span>
          <span class="k">raise</span> <span class="ne">Exception</span><span class="p">((</span><span class="sa">f</span><span class="s1">&#39;Second element of the input tuple should one &#39;</span>
                           <span class="sa">f</span><span class="s1">&#39;among: [&quot;asc&quot;, &quot;desc&quot;]. &#39;</span>
                           <span class="sa">f</span><span class="s1">&#39;Input: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s1">&#39;</span>
                           <span class="p">))</span>
        
        <span class="k">assert</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="n">cns</span><span class="p">,</span>\
          <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;String input to &#39;order_by&#39; should be a valid column name. &quot;</span>
           <span class="sa">f</span><span class="s2">&quot;Input: </span><span class="si">{</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
           <span class="p">)</span>
        
        <span class="n">out</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      
      <span class="c1"># case 2: string</span>
      <span class="c1"># prototypes:</span>
      <span class="c1"># &#39;col_a&#39;</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">cns</span><span class="p">,</span>\
          <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;String input to &#39;order_by&#39; should be a valid column name. &quot;</span>
           <span class="sa">f</span><span class="s2">&quot;Input: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">&quot;</span>
           <span class="p">)</span>
        <span class="n">out</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
      
      <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">((</span><span class="s2">&quot;An element of &#39;order_by&#39; should be a tuple or &quot;</span>
                         <span class="s2">&quot;a string&quot;</span>
                         <span class="p">))</span>
      
    <span class="k">return</span> <span class="n">out</span></div>
    
<div class="viewcode-block" id="acc_on_pyspark._create_windowspec"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._create_windowspec">[docs]</a>  <span class="k">def</span> <span class="nf">_create_windowspec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    _create_windowspec</span>
<span class="sd">    Create Window object using relevant kwargs</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    **kwargs : </span>
<span class="sd">      Supports these: by, order_by, range_between, rows_between.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    an instance of pyspark.sql.window.WindowSpec</span>
<span class="sd">    </span>
<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    _create_windowspec does not validates inputs</span>
<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="n">valid_kwarg_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;by&quot;</span><span class="p">,</span> <span class="s2">&quot;order_by&quot;</span><span class="p">,</span> <span class="s2">&quot;range_between&quot;</span><span class="p">,</span> <span class="s2">&quot;rows_between&quot;</span><span class="p">]</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">valid_kwarg_names</span><span class="p">),</span>\
      <span class="sa">f</span><span class="s2">&quot;Input kwarg should have one of these names: </span><span class="si">{</span><span class="n">valid_kwarg_names</span><span class="si">}</span><span class="s2">&quot;</span>
    
    <span class="k">if</span> <span class="s1">&#39;by&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="n">win</span> <span class="o">=</span> <span class="n">Window</span><span class="o">.</span><span class="n">partitionBy</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;by&#39;</span><span class="p">])</span>
    
    <span class="k">if</span> <span class="s1">&#39;order_by&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="k">if</span> <span class="s1">&#39;win&#39;</span> <span class="ow">in</span> <span class="nb">locals</span><span class="p">():</span>
        <span class="n">win</span> <span class="o">=</span> <span class="n">win</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;order_by&#39;</span><span class="p">])</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">win</span> <span class="o">=</span> <span class="n">Window</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;order_by&#39;</span><span class="p">])</span>
            
    <span class="k">if</span> <span class="s1">&#39;range_between&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="n">win</span> <span class="o">=</span> <span class="n">win</span><span class="o">.</span><span class="n">rangeBetween</span><span class="p">(</span><span class="o">*</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;range_between&#39;</span><span class="p">])</span>
    
    <span class="k">if</span> <span class="s1">&#39;rows_between&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="n">win</span> <span class="o">=</span> <span class="n">win</span><span class="o">.</span><span class="n">rowsBetween</span><span class="p">(</span><span class="o">*</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;rows_between&#39;</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">win</span></div>
  
  <span class="c1"># utils -------------------------------------------------------------------</span>

<div class="viewcode-block" id="acc_on_pyspark.glimpse"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.glimpse">[docs]</a>  <span class="k">def</span> <span class="nf">glimpse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_rows</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_columns</span> <span class="o">=</span> <span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    glimpse</span>

<span class="sd">    This function prints the first 100(default) rows of the dataset, along with</span>
<span class="sd">    the number of rows and columns in the dataset and the data types of each</span>
<span class="sd">    column. It also displays the values of each column, limited to the first</span>
<span class="sd">    100 (default) values. If the number of rows exceeds 100, then the values are</span>
<span class="sd">    truncated accordingly.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_columns : maximum number of columns to be handled</span>
<span class="sd">    n_rows: maximum number of rows to show</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    None</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.glimpse()</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">get_terminal_size</span>
    <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">get_terminal_size</span><span class="p">()</span>

    <span class="c1"># get row and column count</span>
    <span class="n">ncol</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;Columns: </span><span class="si">{</span><span class="n">ncol</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span>

    <span class="n">names</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_ljust</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dtypes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">t_ljust</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Input validation</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">n_rows</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span>\
      <span class="s2">&quot;n_rows must be a positive integer&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n_columns</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">n_columns</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span>\
      <span class="s2">&quot;n_columns must be a positive integer&quot;</span>

    <span class="c1">#get dtypes for all columns</span>
    <span class="n">data_temp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="n">n_rows</span><span class="p">)</span><span class="o">.</span><span class="n">toPandas</span><span class="p">()</span>
    <span class="n">all_dtypes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">types</span>

    <span class="k">for</span> <span class="n">acol</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n_columns</span><span class="p">]:</span>
      <span class="n">names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acol</span><span class="p">)</span>
      <span class="n">n_ljust</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">n_ljust</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
      <span class="n">dtypes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;&lt;</span><span class="si">{</span><span class="n">all_dtypes</span><span class="p">[</span><span class="n">acol</span><span class="p">]</span><span class="si">}</span><span class="s1">&gt;&#39;</span><span class="p">)</span>
      <span class="n">t_ljust</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">t_ljust</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dtypes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

    <span class="c1">#get values for float and non float columns</span>
    <span class="n">float_vals_precision</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">dtype</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">dtypes</span><span class="p">):</span>
      <span class="n">vals</span> <span class="o">=</span> <span class="n">data_temp</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">name</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">dtype</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">6</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;float&quot;</span><span class="p">:</span>
          <span class="n">vals</span> <span class="o">=</span> <span class="n">vals</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">float_vals_precision</span><span class="p">)</span>
      <span class="n">val_str</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">vals</span><span class="p">)))</span>

      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_str</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">w</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">n_ljust</span><span class="o">-</span><span class="n">t_ljust</span><span class="p">:</span>
          <span class="n">val_str</span> <span class="o">=</span> <span class="n">val_str</span><span class="p">[</span><span class="mi">0</span><span class="p">:(</span><span class="n">w</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">n_ljust</span><span class="o">-</span><span class="n">t_ljust</span><span class="p">)</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;...&quot;</span>
      <span class="n">res_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">name</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">n_ljust</span><span class="p">)</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="n">dtype</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">t_ljust</span><span class="p">)</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="n">val_str</span><span class="si">}</span><span class="s1">&#39;</span>
      <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res_str</span><span class="p">)</span>

    <span class="c1"># print additional columnnames/count in case it is more then n_rows</span>
    <span class="k">if</span> <span class="n">ncol</span> <span class="o">&gt;</span> <span class="n">n_columns</span><span class="p">:</span>
      <span class="n">footer</span> <span class="o">=</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">more columns: &#39;</span>
                <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">colnames</span><span class="p">[</span><span class="n">n_columns</span><span class="p">:(</span><span class="n">n_columns</span><span class="o">+</span><span class="mi">50</span><span class="p">)])</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">ncol</span> <span class="o">&gt;=</span> <span class="n">n_columns</span><span class="o">+</span><span class="mi">50</span><span class="p">:</span>
        <span class="n">footer</span> <span class="o">+=</span> <span class="s2">&quot;...&quot;</span>
        <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">footer</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">res</span><span class="p">))</span>
    <span class="k">return</span> <span class="kc">None</span></div>
  

<div class="viewcode-block" id="acc_on_pyspark.add_row_number"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.add_row_number">[docs]</a>  <span class="k">def</span> <span class="nf">add_row_number</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">order_by</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;row_number&quot;</span><span class="p">,</span> <span class="n">by</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    add_row_number</span>
<span class="sd">    Adds a column indicating row number optionally per group</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    order_by : order by specification</span>
<span class="sd">      How to order before assigning row numbers.</span>
<span class="sd">    name : string, optional</span>
<span class="sd">      Name of the new column. The default is &quot;row_number&quot;.</span>
<span class="sd">    by : string or list of strings, optional</span>
<span class="sd">      Column names to group by. The default is None.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.add_row_number(&#39;bill_length_mm&#39;).show(10)</span>
<span class="sd">    &gt;&gt;&gt; (pen.ts.add_row_number(&#39;bill_length_mm&#39;, by=&#39;species&#39;)</span>
<span class="sd">    &gt;&gt;&gt;     .filter(F.col(&#39;row_number&#39;) &lt;= 2)</span>
<span class="sd">    &gt;&gt;&gt;     .show(10))</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">order_by</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_order_by</span><span class="p">(</span><span class="n">order_by</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span><span class="p">,</span>\
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> should not be an existing column name&quot;</span>
    <span class="k">if</span> <span class="n">by</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">by</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_by</span><span class="p">(</span><span class="n">by</span><span class="p">)</span>
      <span class="n">win</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_windowspec</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="n">by</span><span class="p">,</span> <span class="n">order_by</span> <span class="o">=</span> <span class="n">order_by</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">win</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_windowspec</span><span class="p">(</span><span class="n">order_by</span> <span class="o">=</span> <span class="n">order_by</span><span class="p">)</span>
    
    <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">row_number</span><span class="p">()</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">win</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span></div>
  
  <span class="c1"># alias</span>
  <span class="n">rowid_to_column</span> <span class="o">=</span> <span class="n">add_row_number</span>
  
<div class="viewcode-block" id="acc_on_pyspark.add_group_number"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.add_group_number">[docs]</a>  <span class="k">def</span> <span class="nf">add_group_number</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">by</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;group_number&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    add_group_number</span>
<span class="sd">    Adds group number per group</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    by : string or list of strings</span>
<span class="sd">      Column names to group by</span>
<span class="sd">    name : string, optional</span>
<span class="sd">      Name of the new column to be created. The default is &quot;group_number&quot;.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; (pen.ts.add_row_number(&#39;species&#39;, by = &#39;species&#39;)</span>
<span class="sd">    &gt;&gt;&gt;     .filter(F.col(&#39;row_number&#39;) &lt;= 2)</span>
<span class="sd">    &gt;&gt;&gt;     .drop(&#39;row_number&#39;)</span>
<span class="sd">    &gt;&gt;&gt;     .ts.add_group_number(&#39;species&#39;, name = &#39;gn&#39;)</span>
<span class="sd">    &gt;&gt;&gt;     .show(10)</span>
<span class="sd">    &gt;&gt;&gt;     )</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span><span class="p">,</span>\
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> should not be an existing column name&quot;</span>
    <span class="n">by</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_by</span><span class="p">(</span><span class="n">by</span><span class="p">)</span>
    <span class="n">win</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_windowspec</span><span class="p">(</span><span class="n">order_by</span> <span class="o">=</span> <span class="n">by</span><span class="p">)</span>
    <span class="n">groups_numbered</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
                           <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">by</span><span class="p">)</span>
                           <span class="o">.</span><span class="n">dropDuplicates</span><span class="p">()</span>
                           <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">row_number</span><span class="p">()</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">win</span><span class="p">))</span>
                           <span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">groups_numbered</span><span class="p">,</span> <span class="n">how</span> <span class="o">=</span> <span class="s2">&quot;inner&quot;</span><span class="p">,</span> <span class="n">on</span> <span class="o">=</span> <span class="n">by</span><span class="p">)</span>       
    <span class="k">return</span> <span class="n">res</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark.to_list"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.to_list">[docs]</a>  <span class="k">def</span> <span class="nf">to_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column_name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    to_list</span>
<span class="sd">    collect a column as python list</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    column_name : str</span>
<span class="sd">      Name of the column to be collected.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">column_name</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
    <span class="n">column_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">column_name</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
               <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">column_name</span><span class="p">)</span>
               <span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
               <span class="o">.</span><span class="n">collect</span><span class="p">()</span>
               <span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark.pull"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.pull">[docs]</a>  <span class="k">def</span> <span class="nf">pull</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column_name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    pull</span>
<span class="sd">    collect a column as pandas series</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    column_name : str</span>
<span class="sd">      Name of the column to be collected.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pandas series</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">column_name</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
    <span class="n">column_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">column_name</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
               <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">column_name</span><span class="p">)</span>
               <span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
               <span class="o">.</span><span class="n">collect</span><span class="p">()</span>
               <span class="p">)</span>
    <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="n">column_name</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
      
    <span class="k">return</span> <span class="n">res</span></div>
  
  <span class="c1"># alias for pull</span>
  <span class="n">to_series</span> <span class="o">=</span> <span class="n">pull</span>
  
<div class="viewcode-block" id="acc_on_pyspark.to_dict"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.to_dict">[docs]</a>  <span class="k">def</span> <span class="nf">to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    to_dict</span>
<span class="sd">    collect as a dict where keys are column names and</span>
<span class="sd">    values are lists</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict</span>
<span class="sd">    </span>
<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Each column is pulled separately to reduce the load on the executor.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">res_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">acolname</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span><span class="p">:</span>
      <span class="n">res_dict</span><span class="p">[</span><span class="n">acolname</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
                                <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">acolname</span><span class="p">)</span>
                                <span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                                <span class="o">.</span><span class="n">collect</span><span class="p">()</span>
                                <span class="p">)</span>
    <span class="k">return</span> <span class="n">res_dict</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark.to_pandas"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.to_pandas">[docs]</a>  <span class="k">def</span> <span class="nf">to_pandas</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    to_pandas</span>
<span class="sd">    collect as a pandas dataframe</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pandas dataframe</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">toPandas</span><span class="p">()</span></div>
  
  <span class="c1"># alias: to_pandas</span>
  <span class="n">collect</span> <span class="o">=</span> <span class="n">to_pandas</span>

  <span class="c1"># basic verbs -------------------------------------------------------------</span>
  
<div class="viewcode-block" id="acc_on_pyspark.select"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.select">[docs]</a>  <span class="k">def</span> <span class="nf">select</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column_names</span><span class="p">,</span> <span class="n">include</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    select</span>
<span class="sd">    Subset some columns</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    column_names: (list of strings or a string)</span>
<span class="sd">        Names of the columns to be selected when &#39;include&#39; is True</span>
<span class="sd">    </span>
<span class="sd">    include: (flag, default = True)</span>
<span class="sd">        flag to indicate whether &#39;column_names&#39; should be selected or removed</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.select(&#39;species&#39;).show(10)</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.select([&#39;species&#39;, &#39;island&#39;]).show(10)</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.select([&#39;species&#39;, &#39;island&#39;], include = False).show(10)</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">cn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">column_names</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">include</span><span class="p">:</span>
      <span class="n">cn</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">colnames</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">cn</span><span class="p">))</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cn</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Atleast one column should be selected&quot;</span><span class="p">)</span>
        
    <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">cn</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark.arrange"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.arrange">[docs]</a>  <span class="k">def</span> <span class="nf">arrange</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">order_by</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    arrange</span>
<span class="sd">    Arrange rows</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    order_by : string or tuple or list of tuples</span>
<span class="sd">        Order by specification</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    </span>
<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    1. &#39;arrange&#39; is not memory efficient as it brings all data</span>
<span class="sd">       to a single executor.</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.arrange(&#39;bill_depth_mm&#39;).show(10)</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.arrange([&#39;bill_depth_mm&#39;, (&#39;bill_length_mm&#39;, &#39;desc&#39;)]).show(10)</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">order_by</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_order_by</span><span class="p">(</span><span class="n">order_by</span><span class="p">)</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;1. &#39;arrange&#39; is not memory efficient as it brings all data &quot;</span>
         <span class="s2">&quot;to a single executor&quot;</span>
         <span class="p">)</span>
      
    <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="n">order_by</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>
      
<div class="viewcode-block" id="acc_on_pyspark.distinct"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.distinct">[docs]</a>  <span class="k">def</span> <span class="nf">distinct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column_names</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">order_by</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">keep_all</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    distinct</span>
<span class="sd">    Keep only distinct combinations of columns</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    column_names : string or a list of strings, optional</span>
<span class="sd">      Column names to identify distinct rows. </span>
<span class="sd">      The default is None. All columns are considered.</span>
<span class="sd">    order_by : order_by specification, optional</span>
<span class="sd">      Columns to order by to know which rows to retain. The default is None.</span>
<span class="sd">    keep_all : bool, optional</span>
<span class="sd">      Whether to keep all the columns. The default is False.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.distinct(&#39;island&#39;).show(10)</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.distinct([&#39;species&#39;, &#39;island&#39;]).show(10)</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.distinct([&#39;species&#39;, &#39;island&#39;], keep_all = True).show(10)</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">if</span> <span class="n">column_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">column_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span>
    
    <span class="n">cn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">column_names</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">order_by</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">dropDuplicates</span><span class="p">(</span><span class="n">cn</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">order_by</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_order_by</span><span class="p">(</span><span class="n">order_by</span><span class="p">)</span>
      <span class="n">win</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_windowspec</span><span class="p">(</span><span class="n">order_by</span> <span class="o">=</span> <span class="n">order_by</span><span class="p">)</span>
      <span class="n">rank_colname</span> <span class="o">=</span> <span class="n">_generate_new_string</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">colnames</span><span class="p">)</span>
      
      <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
                 <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">rank_colname</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">row_number</span><span class="p">()</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">win</span><span class="p">))</span>
                 <span class="o">.</span><span class="n">dropDuplicates</span><span class="p">(</span><span class="n">cn</span> <span class="o">+</span> <span class="p">[</span><span class="n">rank_colname</span><span class="p">])</span>
                 <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">rank_colname</span><span class="p">)</span>
                 <span class="p">)</span>
        
    <span class="k">if</span> <span class="ow">not</span> <span class="n">keep_all</span><span class="p">:</span>
      <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">cn</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">res</span></div>

<div class="viewcode-block" id="acc_on_pyspark.rename"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.rename">[docs]</a>  <span class="k">def</span> <span class="nf">rename</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">old_new_dict</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    rename</span>
<span class="sd">    Rename columns</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    old_new_dict: dict</span>
<span class="sd">      A dict with old names as keys and new names as values</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.rename({&#39;species&#39;: &#39;species_2&#39;, &quot;year&quot;:&quot;year_2})</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">cn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span>

    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">old_new_dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">),</span> \
      <span class="s2">&quot;arg &#39;old_new_dict&#39; should be a dict&quot;</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">old_new_dict</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> \
      <span class="s2">&quot;There should alteast one element in old_new_dict&quot;</span>
    
    <span class="n">new_column_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">old_new_dict</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">cn</span><span class="p">)</span><span class="o">.</span><span class="n">issuperset</span><span class="p">(</span><span class="n">old_new_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()),</span> \
      <span class="s2">&quot;Keys of the input dict should be existing column names&quot;</span>
    <span class="k">assert</span> <span class="n">_is_unique_list</span><span class="p">(</span><span class="n">new_column_names</span><span class="p">),</span> \
      <span class="s2">&quot;Values of the dict should be unique&quot;</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><span class="n">_is_valid_colname</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">new_column_names</span><span class="p">]),</span>\
      <span class="s2">&quot;Atleast one value of the dict is not a valid column name&quot;</span>
    
    <span class="c1"># new names should not intersect with &#39;remaining&#39; names</span>
    <span class="n">remaining</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">cn</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">old_new_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">remaining</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">old_new_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> \
      <span class="p">(</span><span class="s2">&quot;New intended column names (values of the dict) should not lead to &quot;</span>     
       <span class="s2">&quot;duplicate column names&quot;</span>
       <span class="p">)</span>
    <span class="n">select_col_with_alias</span> <span class="o">=</span> <span class="p">([</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">old_new_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
                             <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span><span class="p">])</span>
    <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">select_col_with_alias</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>

<div class="viewcode-block" id="acc_on_pyspark.relocate"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.relocate">[docs]</a>  <span class="k">def</span> <span class="nf">relocate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column_names</span><span class="p">,</span> <span class="n">before</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">after</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    relocate</span>
<span class="sd">    Relocate the columns</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    column_names : string or a list of strings</span>
<span class="sd">      column names to be moved</span>
<span class="sd">    before : string, optional</span>
<span class="sd">      column before which the column_names are to be moved.</span>
<span class="sd">      The default is None.</span>
<span class="sd">    after : string, optional</span>
<span class="sd">      column after which the column_names are to be moved.</span>
<span class="sd">      The default is None.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Only one among &#39;before&#39; and &#39;after&#39; can be not None. When both are None,</span>
<span class="sd">    the columns are added to the beginning of the dataframe (leftmost)</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; # move &quot;island&quot; and &quot;species&quot; columns to the left of the dataframe</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.relocate([&quot;island&quot;, &quot;species&quot;])</span>
<span class="sd">    &gt;&gt;&gt; # move &quot;sex&quot; and &quot;year&quot; columns to the left of &quot;island&quot; column</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.relocate([&quot;sex&quot;, &quot;year&quot;], before = &quot;island&quot;)</span>
<span class="sd">    &gt;&gt;&gt; # move &quot;island&quot; and &quot;species&quot; columns to the right of &quot;year&quot; column</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.relocate([&quot;island&quot;, &quot;species&quot;], after = &quot;year&quot;)</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">column_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">column_names</span><span class="p">)</span>
    <span class="n">cn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span>

    <span class="n">cn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span>
    <span class="n">col_not_relocate</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cn</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">column_names</span><span class="p">]</span>

    <span class="k">assert</span> <span class="ow">not</span> <span class="p">((</span><span class="n">before</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">after</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)),</span> \
      <span class="s2">&quot;Atleast one arg among &#39;before&#39; and &#39;after&#39; should be None&quot;</span>

    <span class="k">if</span> <span class="n">after</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">after</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> \
        <span class="s2">&quot;arg &#39;after&#39; should be a string&quot;</span>
      <span class="k">assert</span> <span class="n">after</span> <span class="ow">in</span> <span class="n">cn</span><span class="p">,</span> \
        <span class="s2">&quot;arg &#39;after&#39; should be a exisiting column name&quot;</span>
      <span class="k">assert</span> <span class="ow">not</span> <span class="p">(</span><span class="n">after</span> <span class="ow">in</span> <span class="n">column_names</span><span class="p">),</span> \
        <span class="s2">&quot;arg &#39;after&#39; should be an element of &#39;column_names&#39;&quot;</span>

    <span class="k">if</span> <span class="n">before</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">before</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> \
        <span class="s2">&quot;arg &#39;before&#39; should be a string&quot;</span>
      <span class="k">assert</span> <span class="n">before</span> <span class="ow">in</span> <span class="n">cn</span><span class="p">,</span> \
        <span class="s2">&quot;arg &#39;before&#39; should be a exisiting column name&quot;</span>
      <span class="k">assert</span> <span class="ow">not</span> <span class="p">(</span><span class="n">before</span> <span class="ow">in</span> <span class="n">column_names</span><span class="p">),</span> \
        <span class="s2">&quot;arg &#39;before&#39; should be an element of &#39;column_names&#39;&quot;</span>

    <span class="c1"># case 1: relocate to start when both before and after are None</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">before</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">after</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
      <span class="n">col_sequence</span> <span class="o">=</span> <span class="n">column_names</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">col_not_relocate</span><span class="p">)</span>
    <span class="k">elif</span> <span class="p">(</span><span class="n">before</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
      <span class="c1"># case 2: before is not None</span>
      <span class="n">col_sequence</span> <span class="o">=</span> <span class="n">col_not_relocate</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">col_not_relocate</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">before</span><span class="p">)]</span> <span class="o">+</span> \
                      <span class="n">column_names</span> <span class="o">+</span> \
                      <span class="n">col_not_relocate</span><span class="p">[</span><span class="n">col_not_relocate</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">before</span><span class="p">):]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># case 3: after is not None</span>
      <span class="n">after_index</span> <span class="o">=</span> <span class="n">col_not_relocate</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">after</span><span class="p">)</span>
      <span class="n">col_sequence</span> <span class="o">=</span> <span class="n">col_not_relocate</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">after_index</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> \
                     <span class="n">column_names</span> <span class="o">+</span> \
                     <span class="n">col_not_relocate</span><span class="p">[</span><span class="n">after_index</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span>

    <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">col_sequence</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>

<div class="viewcode-block" id="acc_on_pyspark.mutate"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.mutate">[docs]</a>  <span class="k">def</span> <span class="nf">mutate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">window_spec</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    mutate</span>
<span class="sd">    Create new column or modify existing columns</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    dictionary : dict</span>
<span class="sd">      key should be new/existing column name. </span>
<span class="sd">      Value should is pyspark expression that should evaluate to a column</span>
<span class="sd">    window_spec : pyspark.sql.window.WindowSpec, optional</span>
<span class="sd">      The default is None.</span>
<span class="sd">    **kwargs : Supports these: by, order_by, range_between, rows_between.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">      </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; (pen.ts.mutate({&#39;bl_+_1&#39;: F.col(&#39;bill_length_mm&#39;) + 1,</span>
<span class="sd">    &gt;&gt;&gt;                  &#39;bl_+_1_by_2&#39;: F.col(&#39;bl_+_1&#39;) / 2})</span>
<span class="sd">    &gt;&gt;&gt;     .show(10)</span>
<span class="sd">    &gt;&gt;&gt;     )</span>
<span class="sd">    &gt;&gt;&gt; # grouped and order mutate operation</span>
<span class="sd">    &gt;&gt;&gt; (pen.ts.add_row_number(order_by = &#39;bill_depth_mm&#39;)</span>
<span class="sd">    &gt;&gt;&gt;     .ts.mutate({&#39;cumsum_bl&#39;: F.sum(&#39;bill_length_mm&#39;)},</span>
<span class="sd">    &gt;&gt;&gt;                by = &#39;species&#39;,</span>
<span class="sd">    &gt;&gt;&gt;                order_by = [&#39;bill_depth_mm&#39;, &#39;row_number&#39;],</span>
<span class="sd">    &gt;&gt;&gt;                range_between = (-float(&#39;inf&#39;), 0)</span>
<span class="sd">    &gt;&gt;&gt;                )</span>
<span class="sd">    &gt;&gt;&gt;     .ts.select([&#39;bill_length_mm&#39;,</span>
<span class="sd">    &gt;&gt;&gt;                 &#39;species&#39;,</span>
<span class="sd">    &gt;&gt;&gt;                 &#39;bill_depth_mm&#39;,</span>
<span class="sd">    &gt;&gt;&gt;                 &#39;cumsum_bl&#39;</span>
<span class="sd">    &gt;&gt;&gt;                 ])</span>
<span class="sd">    &gt;&gt;&gt;     .show(10)</span>
<span class="sd">    &gt;&gt;&gt;     )</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><span class="n">_is_valid_colname</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">keys</span><span class="p">()]),</span>\
      <span class="s2">&quot;Atleast one key of the dictionary is not a valid column name&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
  
    <span class="n">with_win</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="c1"># windowspec gets first preference</span>
    <span class="k">if</span> <span class="n">window_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">with_win</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">window_spec</span><span class="p">,</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">window</span><span class="o">.</span><span class="n">WindowSpec</span><span class="p">),</span>\
        <span class="p">(</span><span class="s2">&quot;&#39;window_spec&#39; should be an instance of &quot;</span>
         <span class="s2">&quot;&#39;pyspark.sql.window.WindowSpec&#39; class&quot;</span>
         <span class="p">)</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&#39;window_spec&#39; takes precedence over other kwargs&quot;</span>
              <span class="s2">&quot; in mutate&quot;</span>
              <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># create windowspec if required</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">akwarg_name</span><span class="p">,</span> <span class="n">akwarg_value</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
          <span class="k">if</span> <span class="n">akwarg_name</span> <span class="o">==</span> <span class="s2">&quot;by&quot;</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="n">akwarg_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_by</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="n">akwarg_name</span><span class="p">])</span>
          <span class="k">if</span> <span class="n">akwarg_name</span> <span class="o">==</span> <span class="s2">&quot;order_by&quot;</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="n">akwarg_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_order_by</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="n">akwarg_name</span><span class="p">])</span>
        <span class="n">win</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_windowspec</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">with_win</span> <span class="o">=</span> <span class="kc">True</span>
    
    <span class="c1"># create one column at a time</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">with_win</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">win</span><span class="p">))</span>
            
    <span class="k">return</span> <span class="n">res</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark.summarise"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.summarise">[docs]</a>  <span class="k">def</span> <span class="nf">summarise</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">by</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    summarise</span>
<span class="sd">    Create aggregate columns</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    dictionary : dict</span>
<span class="sd">      key should be column name. </span>
<span class="sd">      Value should is pyspark expression that should produce a single</span>
<span class="sd">      aggregation value</span>
<span class="sd">    by : string or list of strings</span>
<span class="sd">      Column names to group by</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">      </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; # ungrouped summarise</span>
<span class="sd">    &gt;&gt;&gt; (pen.ts.summarise({&#39;mean_bl&#39;: F.mean(F.col(&#39;bill_length_mm&#39;)),</span>
<span class="sd">    &gt;&gt;&gt;                    &#39;count_species&#39;: F.count(F.col(&#39;species&#39;))</span>
<span class="sd">    &gt;&gt;&gt;                   }</span>
<span class="sd">    &gt;&gt;&gt;                  )</span>
<span class="sd">    &gt;&gt;&gt;     .show(10)</span>
<span class="sd">    &gt;&gt;&gt;     )</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; # grouped summarise</span>
<span class="sd">    &gt;&gt;&gt; (pen.ts.summarise({&#39;mean_bl&#39;: F.mean(F.col(&#39;bill_length_mm&#39;)),</span>
<span class="sd">    &gt;&gt;&gt;                    &#39;count_species&#39;: F.count(F.col(&#39;species&#39;))</span>
<span class="sd">    &gt;&gt;&gt;                   },</span>
<span class="sd">    &gt;&gt;&gt;                   by = &#39;island&#39;</span>
<span class="sd">    &gt;&gt;&gt;                  )</span>
<span class="sd">    &gt;&gt;&gt;     .show(10)</span>
<span class="sd">    &gt;&gt;&gt;     )</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><span class="n">_is_valid_colname</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">keys</span><span class="p">()]),</span>\
      <span class="s2">&quot;Atleast one key of the dictionary is not a valid column name&quot;</span>
    <span class="n">agg_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">tup</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">tup</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
    
    <span class="k">if</span> <span class="n">by</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="o">*</span><span class="n">agg_list</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">by</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_by</span><span class="p">(</span><span class="n">by</span><span class="p">)</span>
      <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="o">*</span><span class="n">by</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="o">*</span><span class="n">agg_list</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">res</span></div>
  
  <span class="n">summarize</span> <span class="o">=</span> <span class="n">summarise</span>
  
<div class="viewcode-block" id="acc_on_pyspark.filter"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.filter">[docs]</a>  <span class="k">def</span> <span class="nf">filter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">condition</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    filter</span>
<span class="sd">    subset rows using some condition</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    condition : pyspark column or string</span>
<span class="sd">      Column of types.BooleanType or a string of SQL expression.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">condition</span><span class="p">)</span></div>
    
  <span class="c1"># join methods ------------------------------------------------------------</span>
<div class="viewcode-block" id="acc_on_pyspark._validate_join"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._validate_join">[docs]</a>  <span class="k">def</span> <span class="nf">_validate_join</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pyspark_df</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">on_x</span><span class="p">,</span> <span class="n">on_y</span> <span class="p">,</span> <span class="n">sql_on</span><span class="p">,</span> <span class="n">suffix</span><span class="p">,</span> <span class="n">how</span><span class="p">):</span>
      
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pyspark_df</span><span class="p">,</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">dataframe</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">),</span>\
      <span class="s2">&quot;&#39;pyspark_df&#39; should be a pyspark dataframe&quot;</span>
    
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">how</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span>\
      <span class="s2">&quot;arg &#39;how&#39; should be a string&quot;</span>
    <span class="n">valid_joins</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;inner&#39;</span><span class="p">,</span> <span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="s1">&#39;full&#39;</span><span class="p">,</span> <span class="s1">&#39;semi&#39;</span><span class="p">,</span> <span class="s1">&#39;anti&#39;</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">how</span> <span class="ow">in</span> <span class="n">valid_joins</span><span class="p">,</span>\
      <span class="sa">f</span><span class="s2">&quot;arg &#39;how&#39; should be one among: </span><span class="si">{</span><span class="n">valid_joins</span><span class="si">}</span><span class="s2">&quot;</span>
    
    <span class="n">cn_y</span> <span class="o">=</span> <span class="n">pyspark_df</span><span class="o">.</span><span class="n">columns</span>
    <span class="k">assert</span> <span class="n">_is_unique_list</span><span class="p">(</span><span class="n">cn_y</span><span class="p">),</span>\
      <span class="s2">&quot;column names of &#39;pyspark_df&#39; should be unique&quot;</span>
  
    <span class="k">assert</span> <span class="p">((</span><span class="n">on</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> 
            <span class="o">+</span> <span class="p">((</span><span class="n">on_x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">on_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">))</span> 
            <span class="o">+</span> <span class="p">(</span><span class="n">sql_on</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span>\
      <span class="s2">&quot;Exactly one among &#39;on&#39;, &#39;sql_on&#39;, &#39;on_x and on_y&#39; should be specified&quot;</span>
  
    <span class="k">if</span> <span class="n">on</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">on</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">on</span><span class="p">)</span>
      <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">on</span><span class="p">)</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">cn_y</span><span class="p">),</span>\
        <span class="s2">&quot;arg &#39;on&#39; should be a subset of column names of y&quot;</span>
    <span class="k">elif</span> <span class="n">sql_on</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sql_on</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span>\
        <span class="s2">&quot;arg &#39;sql_on&#39; should be a string&quot;</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">assert</span> <span class="n">on_x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">on_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span>\
        <span class="p">(</span><span class="s2">&quot;When arg &#39;on&#39; is None, &quot;</span> 
          <span class="s2">&quot;both args &#39;on_x&#39; and &#39;on_y&#39; should be present&quot;</span>
        <span class="p">)</span>
        
      <span class="n">on_x</span> <span class="o">=</span> <span class="n">_enlist</span><span class="p">(</span><span class="n">on_x</span><span class="p">)</span>
      <span class="n">on_y</span> <span class="o">=</span> <span class="n">_enlist</span><span class="p">(</span><span class="n">on_y</span><span class="p">)</span>
      
      <span class="n">on_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">on_x</span><span class="p">)</span>
      
      <span class="k">assert</span> <span class="n">_is_string_or_string_list</span><span class="p">(</span><span class="n">on_y</span><span class="p">),</span>\
        <span class="s2">&quot;arg &#39;on_y&#39; should be a string or a list of strings&quot;</span>
      
      <span class="k">assert</span> <span class="n">_is_unique_list</span><span class="p">(</span><span class="n">on_y</span><span class="p">),</span>\
        <span class="s2">&quot;arg &#39;on_y&#39; should not have duplicates&quot;</span>    
      <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">on_y</span><span class="p">)</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">cn_y</span><span class="p">),</span>\
        <span class="s2">&quot;arg &#39;on_y&#39; should be a subset of column names of y&quot;</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">on_x</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">on_y</span><span class="p">),</span>\
        <span class="s2">&quot;Lengths of arg &#39;on_x&#39; and arg &#39;on_y&#39; should match&quot;</span>
      
    <span class="k">assert</span> <span class="n">_is_string_or_string_list</span><span class="p">(</span><span class="n">suffix</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">suffix</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span>\
      <span class="s2">&quot;arg &#39;suffix&#39; should be a list of strings of length 2&quot;</span>
    
    <span class="k">assert</span> <span class="n">suffix</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">suffix</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>\
      <span class="s2">&quot;left and right suffix should be different.&quot;</span>
    
    <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="acc_on_pyspark._execute_on_command_for_join"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._execute_on_command_for_join">[docs]</a>  <span class="k">def</span> <span class="nf">_execute_on_command_for_join</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">suffix</span><span class="p">,</span> <span class="n">how</span><span class="p">,</span> <span class="n">LHS</span><span class="p">,</span> <span class="n">RHS</span><span class="p">):</span>
          
    <span class="n">on</span> <span class="o">=</span> <span class="n">_enlist</span><span class="p">(</span><span class="n">on</span><span class="p">)</span>
    <span class="n">cols_LHS</span> <span class="o">=</span> <span class="n">LHS</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">cols_RHS</span> <span class="o">=</span> <span class="n">RHS</span><span class="o">.</span><span class="n">columns</span>

    <span class="c1"># Create a dictionary with old column names as keys and values </span>
    <span class="c1"># as old column names + suffix</span>
    <span class="n">new_cols_LHS</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">setlist</span><span class="p">(</span><span class="n">cols_LHS</span><span class="p">)</span> <span class="o">-</span> <span class="n">setlist</span><span class="p">(</span><span class="n">on</span><span class="p">))</span>
    <span class="n">old_new_dict_LHS</span> <span class="o">=</span> <span class="p">{</span><span class="n">col</span><span class="p">:</span> <span class="n">col</span> <span class="o">+</span> <span class="n">suffix</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">new_cols_LHS</span><span class="p">}</span>      

    <span class="c1"># Create a dictionary with old column names as keys and values</span>
    <span class="c1"># as old column names + suffix</span>
    <span class="n">new_cols_RHS</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">setlist</span><span class="p">(</span><span class="n">cols_RHS</span><span class="p">)</span> <span class="o">-</span> <span class="n">setlist</span><span class="p">(</span><span class="n">on</span><span class="p">))</span>
    <span class="n">old_new_dict_RHS</span> <span class="o">=</span> <span class="p">{</span><span class="n">col</span><span class="p">:</span> <span class="n">col</span> <span class="o">+</span> <span class="n">suffix</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">new_cols_RHS</span><span class="p">}</span>

    <span class="n">int_new_cols</span> <span class="o">=</span> <span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">old_new_dict_LHS</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
                    <span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">old_new_dict_RHS</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
                    <span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">int_new_cols</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>\
      <span class="s2">&quot;Resulting column names should be unique after joining the dataframes&quot;</span>
    
    <span class="c1"># Create a list of columns with alias for LHS df in pyspark convention.</span>
    <span class="n">select_col_with_alias_LHS</span> <span class="o">=</span> <span class="p">(</span>
      <span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">old_new_dict_LHS</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
       <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">cols_LHS</span>
       <span class="p">])</span>
    <span class="c1"># Create the new LHS df with the new column names.</span>
    <span class="n">new_LHS</span> <span class="o">=</span> <span class="n">LHS</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">select_col_with_alias_LHS</span><span class="p">)</span>
    
    <span class="c1"># Create a list of columns with alias for RHS df in pyspark convention.</span>
    <span class="n">select_col_with_alias_RHS</span> <span class="o">=</span> <span class="p">(</span>
      <span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">old_new_dict_RHS</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
       <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">cols_RHS</span>
       <span class="p">])</span>
    <span class="c1"># Create the new RHS df with the new column names.</span>
    <span class="n">new_RHS</span> <span class="o">=</span> <span class="n">RHS</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">select_col_with_alias_RHS</span><span class="p">)</span>

    <span class="c1"># Join the dataframes</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">new_LHS</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">new_RHS</span><span class="p">,</span> <span class="n">on</span> <span class="o">=</span> <span class="n">on</span><span class="p">,</span> <span class="n">how</span> <span class="o">=</span> <span class="n">how</span><span class="p">)</span>

    <span class="c1"># Get the count of columns in the original joined dataframe</span>
    <span class="n">count_cols</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">cols_LHS</span> <span class="o">+</span> <span class="n">cols_RHS</span><span class="p">)</span>
    
    <span class="n">renamed_col_dict</span> <span class="o">=</span> <span class="p">{}</span> <span class="c1"># Dictionary to store the renamed columns</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">res</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span> 
      <span class="c1"># use a loop to check each suffix in the list</span>
      <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">suffix</span><span class="p">:</span> 
        <span class="c1"># check if the column name ends with the suffix</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">col</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="n">s</span><span class="p">):</span> 
          <span class="c1"># remove the suffix from the column name</span>
          <span class="n">new_col</span> <span class="o">=</span> <span class="n">col</span><span class="p">[:</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)]</span> 
          <span class="c1"># Check if the new column name is not a duplicate and</span>
          <span class="c1"># is not in the list of columns to be joined</span>
          <span class="k">if</span> <span class="n">count_cols</span><span class="p">[</span><span class="n">new_col</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">new_col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">on</span><span class="p">:</span>      
            <span class="n">renamed_col_dict</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_col</span> 

    <span class="c1"># Rename the columns in the dataframe</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">renamed_col_dict</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">ts</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">renamed_col_dict</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">res</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark._execute_sql_on_command_for_join"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._execute_sql_on_command_for_join">[docs]</a>  <span class="k">def</span> <span class="nf">_execute_sql_on_command_for_join</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sql_on</span><span class="p">,</span> <span class="n">suffix</span><span class="p">,</span> <span class="n">how</span><span class="p">,</span> <span class="n">LHS</span><span class="p">,</span> <span class="n">RHS</span><span class="p">):</span>

    <span class="n">cols_LHS</span> <span class="o">=</span> <span class="n">LHS</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">cols_RHS</span> <span class="o">=</span> <span class="n">RHS</span><span class="o">.</span><span class="n">columns</span>

    <span class="c1"># Create a dictionary with old column names as keys and values</span>
    <span class="c1"># as old column names + suffix</span>
    <span class="n">old_new_dict_LHS</span> <span class="o">=</span> <span class="p">{</span><span class="n">col</span><span class="p">:</span> <span class="n">col</span> <span class="o">+</span> <span class="n">suffix</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cols_LHS</span><span class="p">}</span>
    <span class="n">old_new_dict_RHS</span> <span class="o">=</span> <span class="p">{</span><span class="n">col</span><span class="p">:</span> <span class="n">col</span> <span class="o">+</span> <span class="n">suffix</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cols_RHS</span><span class="p">}</span>

    <span class="n">int_new_cols</span> <span class="o">=</span> <span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">old_new_dict_LHS</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
                    <span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">old_new_dict_RHS</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
                    <span class="p">)</span>
    
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">int_new_cols</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>\
      <span class="s2">&quot;Resulting column names should be unique after joining the dataframes&quot;</span>

    <span class="c1"># Get the column names from the sql_on command.</span>
    <span class="c1"># e.g Format - {&#39;LHS&#39;: [&#39;dept&#39;, &#39;id&#39;], &#39;RHS&#39;: [&#39;dept&#39;, &#39;id&#39;, &#39;age&#39;]}</span>
    <span class="n">column_names_tuple_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_cols_from_sql_on_command</span><span class="p">(</span><span class="n">sql_on</span><span class="p">)</span>
    
    <span class="c1"># Get the sql_on statement with suffix.</span>
    <span class="c1"># e.g Format - &quot;LHS.dept = RHS.dept_y and LHS.id = RHS.id_y&quot;</span>
    <span class="n">sql_on</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_sql_on_statement_with_suffix</span><span class="p">(</span><span class="n">sql_on</span><span class="p">,</span>
                                                    <span class="n">suffix</span><span class="p">,</span>
                                                    <span class="n">column_names_tuple_list</span>
                                                    <span class="p">)</span>

    <span class="c1"># Rename the columns of the LHS and RHS dataframes.</span>
    <span class="n">LHS</span> <span class="o">=</span> <span class="n">LHS</span><span class="o">.</span><span class="n">ts</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">old_new_dict_LHS</span><span class="p">)</span> 
    <span class="n">RHS</span> <span class="o">=</span> <span class="n">RHS</span><span class="o">.</span><span class="n">ts</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">old_new_dict_RHS</span><span class="p">)</span>

    <span class="c1"># Join the dataframes</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">LHS</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">RHS</span><span class="p">,</span> <span class="n">on</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">sql_on</span><span class="p">),</span> <span class="n">how</span> <span class="o">=</span> <span class="n">how</span><span class="p">)</span>

    <span class="c1"># Get the count of columns in the original joined dataframe</span>
    <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_spark_df_by_removing_suffix</span><span class="p">(</span><span class="n">suffix</span><span class="p">,</span>
                                                <span class="n">cols_LHS</span><span class="p">,</span>
                                                <span class="n">cols_RHS</span><span class="p">,</span>
                                                <span class="n">res</span>
                                                <span class="p">)</span>

    <span class="k">return</span> <span class="n">res</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark._execute_on_x_on_y_command_for_join"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._execute_on_x_on_y_command_for_join">[docs]</a>  <span class="k">def</span> <span class="nf">_execute_on_x_on_y_command_for_join</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                          <span class="n">on_x</span><span class="p">,</span>
                                          <span class="n">on_y</span><span class="p">,</span>
                                          <span class="n">suffix</span><span class="p">,</span>
                                          <span class="n">how</span><span class="p">,</span>
                                          <span class="n">LHS</span><span class="p">,</span>
                                          <span class="n">RHS</span><span class="p">):</span>

    <span class="n">on_x</span> <span class="o">=</span> <span class="n">_enlist</span><span class="p">(</span><span class="n">on_x</span><span class="p">)</span>
    <span class="n">on_y</span> <span class="o">=</span> <span class="n">_enlist</span><span class="p">(</span><span class="n">on_y</span><span class="p">)</span>

    <span class="c1"># Degenrate case when on_x and on_y are equal. </span>
    <span class="k">if</span> <span class="n">on_x</span> <span class="o">==</span> <span class="n">on_y</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_on_command_for_join</span><span class="p">(</span><span class="n">on_x</span><span class="p">,</span> <span class="n">suffix</span><span class="p">,</span> <span class="n">how</span><span class="p">,</span> <span class="n">LHS</span><span class="p">,</span> <span class="n">RHS</span><span class="p">)</span>

    <span class="c1"># Generate the sql_on command from on_x and on_y</span>
    <span class="c1"># e.g Format - &quot;(LHS.dept == RHS.dept) &amp; (LHS.id == RHS.id)&quot;</span>
    <span class="n">sql_on</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="c1"># Iterate over the on_x and on_y lists to create the sql_on command.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">on_x</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">sql_on</span> <span class="o">+=</span> <span class="s2">&quot;(LHS.&quot;</span> <span class="o">+</span> <span class="n">on_x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot; == RHS.&quot;</span> <span class="o">+</span> <span class="n">on_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;)&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sql_on</span> <span class="o">+=</span> <span class="s2">&quot; &amp; (LHS.&quot;</span> <span class="o">+</span> <span class="n">on_x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot; == RHS.&quot;</span> <span class="o">+</span> <span class="n">on_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;)&quot;</span>

    <span class="c1"># Execute the sql_on command to return the joined dataframe.</span>
    <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_sql_on_command_for_join</span><span class="p">(</span><span class="n">sql_on</span><span class="p">,</span> <span class="n">suffix</span><span class="p">,</span> <span class="n">how</span><span class="p">,</span> <span class="n">LHS</span><span class="p">,</span> <span class="n">RHS</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">res</span></div>

<div class="viewcode-block" id="acc_on_pyspark._get_sql_on_statement_with_suffix"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._get_sql_on_statement_with_suffix">[docs]</a>  <span class="k">def</span> <span class="nf">_get_sql_on_statement_with_suffix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                        <span class="n">sql_on</span><span class="p">,</span>
                                        <span class="n">suffix</span><span class="p">,</span>
                                        <span class="n">column_names_tuple_list</span><span class="p">):</span>
      
    <span class="c1"># Create a list of column names with suffix for LHS and RHS.</span>
    <span class="c1"># e.g Format - [&#39;LHS.dept&#39;, &#39;LHS.id&#39;, &#39;RHS.dept&#39;, &#39;RHS.id&#39;, &#39;RHS.age&#39;]</span>
    <span class="n">sql_on_LHS_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;LHS.&#39;</span> <span class="o">+</span> <span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">column_names_tuple_list</span><span class="p">[</span><span class="s1">&#39;LHS&#39;</span><span class="p">]]</span>
    <span class="n">sql_on_RHS_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;RHS.&#39;</span> <span class="o">+</span> <span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">column_names_tuple_list</span><span class="p">[</span><span class="s1">&#39;RHS&#39;</span><span class="p">]]</span>

    <span class="c1"># Create a dictionary with old column names as keys and values as </span>
    <span class="c1"># old column names + suffix</span>
    <span class="c1"># e.g Format - {&#39;LHS.dept&#39;: &#39;new_LHS.dept_suffix[0]&#39;, </span>
    <span class="c1">#               &#39;RHS.dept&#39;: &#39;new_RHS.dept_suffix[1]&#39;,</span>
    <span class="c1">#               &#39;RHS.age&#39;: &#39;new_RHS.age_suffix[1]&#39;}</span>
    <span class="n">sql_on_LHS_cols_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">col</span><span class="p">:</span> <span class="n">col</span> <span class="o">+</span> <span class="n">suffix</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">sql_on_LHS_cols</span><span class="p">}</span>
    <span class="n">sql_on_RHS_cols_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">col</span><span class="p">:</span> <span class="n">col</span> <span class="o">+</span> <span class="n">suffix</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">sql_on_RHS_cols</span><span class="p">}</span>
    <span class="c1"># Merge the two dictionaries</span>
    <span class="n">sql_on_cols_dict</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">sql_on_LHS_cols_dict</span><span class="p">,</span> <span class="o">**</span><span class="n">sql_on_RHS_cols_dict</span><span class="p">}</span>
    
    <span class="c1"># Replace the column names in the sql_on command with the new </span>
    <span class="c1"># column names in the sql_on_cols_dict</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">sql_on_cols_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="n">sql_on</span> <span class="o">=</span> <span class="n">sql_on</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">sql_on</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark._extract_cols_from_sql_on_command"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._extract_cols_from_sql_on_command">[docs]</a>  <span class="k">def</span> <span class="nf">_extract_cols_from_sql_on_command</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sql_on</span><span class="p">):</span>

    <span class="c1"># Set regex pattern.</span>
    <span class="c1"># e.g. &#39;LHS.dept == RHS.dept&#39; will be converted to</span>
    <span class="c1"># [(&#39;LHS&#39;, &#39;dept&#39;), (&#39;RHS&#39;, &#39;dept&#39;)]</span>
    <span class="n">pattern</span> <span class="o">=</span> <span class="s1">&#39;([a-zA-Z0-9]+)\.([a-zA-Z0-9]+)&#39;</span>

    <span class="c1"># Get all column names with their table names</span>
    <span class="c1"># Format - [(&#39;LH&#39;, &#39;dept&#39;), (&#39;LHS&#39;, &#39;dept&#39;), (&#39;RHS&#39;, &#39;age&#39;)]</span>
    <span class="n">column_names_tuple_list</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">sql_on</span><span class="p">)</span>

    <span class="c1"># Filtering tuples having only LHS or RHS as the first element of the tuple</span>
    <span class="n">filtered_tuples</span> <span class="o">=</span> <span class="p">([(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> 
                        <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">column_names_tuple_list</span> 
                        <span class="k">if</span> <span class="n">key</span><span class="o">==</span><span class="s1">&#39;LHS&#39;</span> <span class="ow">or</span> <span class="n">key</span><span class="o">==</span><span class="s1">&#39;RHS&#39;</span><span class="p">]</span>
                      <span class="p">)</span>

    <span class="c1"># Generates a dictionary with LHS and RHS as keys and column names as values.</span>
    <span class="c1"># e.g. {&#39;RHS&#39;: [&#39;id2&#39;, &#39;dept&#39;, &#39;age&#39;], &#39;LHS&#39;: [&#39;dept&#39;]}</span>
    <span class="n">dict_from_tuple</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:[]</span> <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="n">filtered_tuples</span><span class="p">}</span>
    <span class="k">for</span> <span class="n">tpl</span> <span class="ow">in</span> <span class="n">filtered_tuples</span><span class="p">:</span>
        <span class="n">dict_from_tuple</span><span class="p">[</span><span class="n">tpl</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tpl</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">dict_from_tuple</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark._get_spark_df_by_removing_suffix"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._get_spark_df_by_removing_suffix">[docs]</a>  <span class="k">def</span> <span class="nf">_get_spark_df_by_removing_suffix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">suffix</span><span class="p">,</span> <span class="n">cols_LHS</span><span class="p">,</span> <span class="n">cols_RHS</span><span class="p">,</span> <span class="n">res</span><span class="p">):</span>
      
    <span class="c1"># Get the frequency count of columns in the original joined dataframe.</span>
    <span class="n">count_cols</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">cols_LHS</span> <span class="o">+</span> <span class="n">cols_RHS</span><span class="p">)</span>
  
    <span class="n">renamed_col_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">res</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span> 
      <span class="c1"># use a loop to check each suffix in the list</span>
      <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">suffix</span><span class="p">:</span>
        <span class="c1"># check if the column name ends with the suffix</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">col</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>  
          <span class="c1"># remove the suffix from the column name</span>
          <span class="n">new_col</span> <span class="o">=</span> <span class="n">col</span><span class="p">[:</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)]</span> 
          <span class="c1"># Check if the new column name is not a duplicate</span>
          <span class="k">if</span> <span class="n">count_cols</span><span class="p">[</span><span class="n">new_col</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">renamed_col_dict</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_col</span>

    <span class="c1"># Rename the columns in the dataframe</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">renamed_col_dict</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">ts</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">renamed_col_dict</span><span class="p">)</span>
      
    <span class="k">return</span> <span class="n">res</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark._execute_cross_join"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._execute_cross_join">[docs]</a>  <span class="k">def</span> <span class="nf">_execute_cross_join</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pyspark_df</span><span class="p">,</span> <span class="n">suffix</span><span class="p">):</span>
      
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pyspark_df</span><span class="p">,</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">dataframe</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">),</span>\
    <span class="s2">&quot;&#39;pyspark_df&#39; should be a pyspark dataframe&quot;</span>
  
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">suffix</span><span class="p">,</span> <span class="nb">list</span><span class="p">),</span>\
    <span class="s2">&quot;arg &#39;suffix&#39; should be a list&quot;</span>
        
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">suffix</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span>\
    <span class="s2">&quot;arg &#39;suffix&#39; should be a list of length 2&quot;</span>
      
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">suffix</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">suffix</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">str</span><span class="p">),</span>\
    <span class="s2">&quot;arg &#39;suffix&#39; should be a list of two strings&quot;</span>
  
    <span class="k">assert</span> <span class="n">suffix</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">suffix</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>\
    <span class="s2">&quot;left and right suffix should be different.&quot;</span>
  
    <span class="n">LHS</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
    <span class="n">RHS</span> <span class="o">=</span> <span class="n">pyspark_df</span>

    <span class="c1"># Get the column names of the LHS and RHS dataframes</span>
    <span class="n">cols_LHS</span> <span class="o">=</span> <span class="n">LHS</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">cols_RHS</span> <span class="o">=</span> <span class="n">RHS</span><span class="o">.</span><span class="n">columns</span>

    <span class="c1"># Create a dictionary with old column names as keys and values</span>
    <span class="c1"># as old column names + suffix</span>
    <span class="n">old_new_dict_LHS</span> <span class="o">=</span> <span class="p">{</span><span class="n">col</span><span class="p">:</span> <span class="n">col</span> <span class="o">+</span> <span class="n">suffix</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cols_LHS</span><span class="p">}</span>
    <span class="n">old_new_dict_RHS</span> <span class="o">=</span> <span class="p">{</span><span class="n">col</span><span class="p">:</span> <span class="n">col</span> <span class="o">+</span> <span class="n">suffix</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cols_RHS</span><span class="p">}</span>
    
    <span class="n">int_new_cols</span> <span class="o">=</span> <span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">old_new_dict_LHS</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
                    <span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">old_new_dict_RHS</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
                    <span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">int_new_cols</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>\
      <span class="s2">&quot;Resulting column names should be unique after joining the dataframes&quot;</span> 
    
    <span class="c1"># Rename the columns in the LHS and RHS dataframes</span>
    <span class="n">LHS</span> <span class="o">=</span> <span class="n">LHS</span><span class="o">.</span><span class="n">ts</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">old_new_dict_LHS</span><span class="p">)</span>
    <span class="n">RHS</span> <span class="o">=</span> <span class="n">RHS</span><span class="o">.</span><span class="n">ts</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">old_new_dict_RHS</span><span class="p">)</span>
  
    <span class="c1"># Perform cross join.</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">LHS</span><span class="o">.</span><span class="n">crossJoin</span><span class="p">(</span><span class="n">RHS</span><span class="p">)</span>

    <span class="c1"># Remove the unnecessary suffix(es) from the column names</span>
    <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_spark_df_by_removing_suffix</span><span class="p">(</span><span class="n">suffix</span><span class="p">,</span>
                                                <span class="n">cols_LHS</span><span class="p">,</span>
                                                <span class="n">cols_RHS</span><span class="p">,</span>
                                                <span class="n">res</span>
                                                <span class="p">)</span>

    <span class="k">return</span> <span class="n">res</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark.join"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.join">[docs]</a>  <span class="k">def</span> <span class="nf">join</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
           <span class="n">pyspark_df</span><span class="p">,</span> 
           <span class="n">on</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
           <span class="n">on_x</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
           <span class="n">on_y</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
           <span class="n">sql_on</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
           <span class="n">suffix</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;_y&quot;</span><span class="p">],</span> 
           <span class="n">how</span> <span class="o">=</span> <span class="s1">&#39;inner&#39;</span>
           <span class="p">):</span> 
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Joins columns of y to self</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pyspark_df (pyspark.sql.DataFrame)</span>
<span class="sd">    on: string or a list of strings</span>
<span class="sd">      Common column names to match</span>
<span class="sd">    on_x: string or a list of strings</span>
<span class="sd">      Column names of self to be matched with arg &#39;on_y&#39;</span>
<span class="sd">    on_y: string or a list of strings</span>
<span class="sd">      Column names of y to be matched with arg &#39;on_x&#39;</span>
<span class="sd">    sql_on: string</span>
<span class="sd">      SQL expression used to join both DataFrames. </span>
<span class="sd">      Recommended for inequality joins.</span>
<span class="sd">      The left table has to be specified as &#39;LHS&#39; and the right table as &#39;RHS&#39;.</span>
<span class="sd">      e.g. &#39;(LHS.dept == RHS.dept) &amp; (LHS.age &gt;= RHS.age) &amp; (RHS.age &lt; 30)&#39;</span>
<span class="sd">    suffix: list of two strings</span>
<span class="sd">      suffix to append the columns of left and right in order to create</span>
<span class="sd">      unique names after the join</span>
<span class="sd">    how: string</span>
<span class="sd">      Type of join to be performed. Default is &#39;inner&#39;.</span>
<span class="sd">      Supports: &#39;inner&#39;, &#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;full&#39;, &#39;cross&#39;,</span>
<span class="sd">                &#39;semi&#39;, &#39;anti&#39;</span>
<span class="sd">      </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; df1 = spark.createDataFrame([</span>
<span class="sd">        (1, &quot;jordan&quot;, &#39;DS&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;DS&#39;),</span>
<span class="sd">        (1, &quot;jack&quot;, &#39;SDE&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;SDE&#39;),</span>
<span class="sd">        (1, &quot;jack&quot;, &#39;PM&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;PM&#39;)</span>
<span class="sd">        ],        </span>
<span class="sd">        (&quot;id&quot;, &quot;name&quot;, &quot;dept&quot;)</span>
<span class="sd">    )</span>

<span class="sd">    &gt;&gt;&gt; df2 = spark.createDataFrame([</span>
<span class="sd">        (2, &quot;SDE&quot;, 20), </span>
<span class="sd">        (1, &quot;SDE&quot;, 10),</span>
<span class="sd">        (2, &quot;PM&quot;, 30),</span>
<span class="sd">        (2, &quot;BA&quot;, 40),</span>
<span class="sd">        ],</span>
<span class="sd">      (&quot;id&quot;, &quot;dept&quot;, &quot;age&quot;)</span>
<span class="sd">    )</span>

<span class="sd">    &gt;&gt;&gt; df1.ts.join(df2, on = [&#39;id&#39;, &#39;dept&#39;], how = &#39;inner).show()</span>
<span class="sd">    +---+----+----+---+</span>
<span class="sd">    | id|dept|name|age|</span>
<span class="sd">    +---+----+----+---+</span>
<span class="sd">    |  1| SDE|jack| 20|</span>
<span class="sd">    |  2|  PM|jack| 30|</span>
<span class="sd">    |  2| SDE|jack| 10|</span>
<span class="sd">    +---+----+----+---+</span>

<span class="sd">    &gt;&gt;&gt; (df1.ts.join(df2, </span>
<span class="sd">    &gt;&gt;&gt;        sql_on = &#39;(LHS.id == RHS.id) &amp; (LHS.dept == RHS.dept) &amp; </span>
<span class="sd">    &gt;&gt;&gt;        (RHS.age &lt; 30)&#39;, how = &#39;inner).show())</span>
<span class="sd">    +---+----+----+----+------+---+</span>
<span class="sd">    | id|name|dept|id_y|dept_y|age|</span>
<span class="sd">    +---+----+----+----+------+---+</span>
<span class="sd">    |  1|jack| SDE|   1|   SDE| 20|</span>
<span class="sd">    |  2|jack| SDE|   2|   SDE| 10|</span>
<span class="sd">    +---+----+----+----+------+---+</span>

<span class="sd">    &#39;&#39;&#39;</span>
 
    <span class="c1"># Special case of cross join.</span>
    <span class="k">if</span> <span class="n">how</span> <span class="o">==</span> <span class="s1">&#39;cross&#39;</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_cross_join</span><span class="p">(</span><span class="n">pyspark_df</span> <span class="o">=</span> <span class="n">pyspark_df</span><span class="p">,</span> <span class="n">suffix</span> <span class="o">=</span> <span class="n">suffix</span><span class="p">)</span>

    <span class="c1"># Validate the input arguments for all joins except cross join.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_validate_join</span><span class="p">(</span><span class="n">pyspark_df</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">on_x</span><span class="p">,</span> <span class="n">on_y</span><span class="p">,</span> <span class="n">sql_on</span><span class="p">,</span> <span class="n">suffix</span><span class="p">,</span> <span class="n">how</span><span class="p">)</span>
   
    <span class="n">LHS</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
    <span class="n">RHS</span> <span class="o">=</span> <span class="n">pyspark_df</span>
  
    <span class="k">if</span> <span class="n">on</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_on_command_for_join</span><span class="p">(</span><span class="n">on</span><span class="p">,</span> <span class="n">suffix</span><span class="p">,</span> <span class="n">how</span><span class="p">,</span> <span class="n">LHS</span><span class="p">,</span> <span class="n">RHS</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">sql_on</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_sql_on_command_for_join</span><span class="p">(</span><span class="n">sql_on</span><span class="p">,</span>
                                                  <span class="n">suffix</span><span class="p">,</span>
                                                  <span class="n">how</span><span class="p">,</span>
                                                  <span class="n">LHS</span><span class="p">,</span> <span class="n">RHS</span>
                                                  <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_on_x_on_y_command_for_join</span><span class="p">(</span><span class="n">on_x</span><span class="p">,</span> <span class="n">on_y</span><span class="p">,</span>
                                                     <span class="n">suffix</span><span class="p">,</span>
                                                     <span class="n">how</span><span class="p">,</span>
                                                     <span class="n">LHS</span><span class="p">,</span> <span class="n">RHS</span>
                                                     <span class="p">)</span>

    <span class="k">return</span> <span class="n">res</span></div>

<div class="viewcode-block" id="acc_on_pyspark.left_join"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.left_join">[docs]</a>  <span class="k">def</span> <span class="nf">left_join</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                <span class="n">pyspark_df</span><span class="p">,</span> 
                <span class="n">on</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                <span class="n">on_x</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                <span class="n">on_y</span> <span class="o">=</span> <span class="kc">None</span> <span class="p">,</span> 
                <span class="n">sql_on</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                <span class="n">suffix</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;_y&quot;</span><span class="p">]</span>
                <span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Joins columns of the given pyspark_df to self by matching rows.</span>
<span class="sd">    Includes all keys from self.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pyspark_df (pyspark.sql.DataFrame)</span>
<span class="sd">    on: string or a list of strings</span>
<span class="sd">      Common column names to match</span>
<span class="sd">    on_x: string or a list of strings</span>
<span class="sd">      Column names of self to be matched with arg &#39;on_y&#39;</span>
<span class="sd">    on_y: string or a list of strings</span>
<span class="sd">      Column names of y to be matched with arg &#39;on_x&#39;</span>
<span class="sd">    sql_on: string</span>
<span class="sd">      SQL expression used to join both DataFrames. </span>
<span class="sd">      Recommended for inequality joins.</span>
<span class="sd">      The left table has to be specified as &#39;LHS&#39; and the right table as &#39;RHS&#39;.</span>
<span class="sd">      e.g. &#39;(LHS.dept == RHS.dept) &amp; (LHS.age &gt;= RHS.age) &amp; (RHS.age &lt; 30)&#39;</span>
<span class="sd">    suffix: list of two strings</span>
<span class="sd">      suffix to append the columns of left and right in order to create</span>
<span class="sd">      unique names after the join</span>
<span class="sd">      </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    # Create the DataFrames</span>
<span class="sd">    &gt;&gt;&gt; df1 = spark.createDataFrame([</span>
<span class="sd">        (1, &quot;jordan&quot;, &#39;DS&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;DS&#39;),</span>
<span class="sd">        (1, &quot;jack&quot;, &#39;SDE&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;SDE&#39;),</span>
<span class="sd">        (1, &quot;jack&quot;, &#39;PM&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;PM&#39;)</span>
<span class="sd">        ],        </span>
<span class="sd">        (&quot;id&quot;, &quot;name&quot;, &quot;dept&quot;)</span>
<span class="sd">    )</span>

<span class="sd">    &gt;&gt;&gt; df2 = spark.createDataFrame([</span>
<span class="sd">        (2, &quot;SDE&quot;, 20), </span>
<span class="sd">        (1, &quot;SDE&quot;, 10),</span>
<span class="sd">        (2, &quot;PM&quot;, 30),</span>
<span class="sd">        (2, &quot;BA&quot;, 40),</span>
<span class="sd">        ],</span>
<span class="sd">      (&quot;id&quot;, &quot;dept&quot;, &quot;age&quot;)</span>
<span class="sd">    )</span>

<span class="sd">    &gt;&gt;&gt; df1.ts.left_join(df2, on = [&quot;id&quot;, &quot;dept&quot;]).show()</span>
<span class="sd">    +---+-----+----+---+---+</span>
<span class="sd">    | id|dept|  name| age|</span>
<span class="sd">    +---+----+------+----+</span>
<span class="sd">    |  1|  DS|jordan|null|</span>
<span class="sd">    |  2|  DS|  jack|null|</span>
<span class="sd">    |  1| SDE|  jack|  10|</span>
<span class="sd">    |  2| SDE|  jack|  20|</span>
<span class="sd">    |  1|  PM|  jack|null|</span>
<span class="sd">    |  2|  PM|  jack|  30|</span>
<span class="sd">    +---+----+------+----+</span>

<span class="sd">    &gt;&gt;&gt; (df1.ts.left_join(df2, sql_on = &#39;(LHS.id == RHS.id) &amp; </span>
<span class="sd">    &gt;&gt;&gt;                   (LHS.dept == RHS.dept) &amp; (RHS.age &lt; 30)&#39;).show())</span>
<span class="sd">    +---+------+----+----+------+----+</span>
<span class="sd">    | id|  name|dept|id_y|dept_y| age|</span>
<span class="sd">    +---+------+----+----+------+----+</span>
<span class="sd">    |  1|jordan|  DS|null|  null|null|</span>
<span class="sd">    |  2|  jack|  DS|null|  null|null|</span>
<span class="sd">    |  1|  jack| SDE|   1|   SDE|  20|</span>
<span class="sd">    |  2|  jack| SDE|   2|   SDE|  10|</span>
<span class="sd">    |  1|  jack|  PM|null|  null|null|</span>
<span class="sd">    |  2|  jack|  PM|null|  null|null|</span>
<span class="sd">    +---+------+----+----+------+----+</span>

<span class="sd">    &gt;&gt;&gt; df1.ts.left_join(df2, on_x = [&#39;name&#39;], on_y = [&#39;dept&#39;]).show()</span>
<span class="sd">    +---+------+----+----+------+----+</span>
<span class="sd">    | id|  name|dept|id_y|dept_y| age|</span>
<span class="sd">    +---+------+----+----+------+----+</span>
<span class="sd">    |  1|jordan|  DS|null|  null|null|</span>
<span class="sd">    |  2|  jack|  DS|null|  null|null|</span>
<span class="sd">    |  1|  jack| SDE|null|  null|null|</span>
<span class="sd">    |  2|  jack| SDE|null|  null|null|</span>
<span class="sd">    |  1|  jack|  PM|null|  null|null|</span>
<span class="sd">    |  2|  jack|  PM|null|  null|null|</span>
<span class="sd">    +---+------+----+----+------+----+</span>

<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pyspark_df</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">on_x</span><span class="p">,</span> <span class="n">on_y</span><span class="p">,</span> <span class="n">sql_on</span><span class="p">,</span> <span class="n">suffix</span><span class="p">,</span> <span class="s1">&#39;left&#39;</span><span class="p">)</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark.right_join"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.right_join">[docs]</a>  <span class="k">def</span> <span class="nf">right_join</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                 <span class="n">pyspark_df</span><span class="p">,</span> 
                 <span class="n">on</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                 <span class="n">on_x</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                 <span class="n">on_y</span> <span class="o">=</span> <span class="kc">None</span> <span class="p">,</span> 
                 <span class="n">sql_on</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                 <span class="n">suffix</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;_y&quot;</span><span class="p">]</span>
                 <span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Joins columns of pyspark_df to self by matching rows</span>
<span class="sd">    Includes all keys in pyspark_df</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pyspark_df (pyspark.sql.DataFrame)</span>
<span class="sd">    on: string or a list of strings</span>
<span class="sd">      Common column names to match</span>
<span class="sd">    on_x: string or a list of strings</span>
<span class="sd">      Column names of self to be matched with arg &#39;on_y&#39;</span>
<span class="sd">    on_y: string or a list of strings</span>
<span class="sd">      Column names of y to be matched with arg &#39;on_x&#39;</span>
<span class="sd">    sql_on: string</span>
<span class="sd">      SQL expression used to join both DataFrames. </span>
<span class="sd">      Recommended for inequality joins.</span>
<span class="sd">      The left table has to be specified as &#39;LHS&#39; and the right table as &#39;RHS&#39;.</span>
<span class="sd">      e.g. &#39;(LHS.dept == RHS.dept) &amp; (LHS.age &gt;= RHS.age) &amp; (RHS.age &lt; 30)&#39;</span>
<span class="sd">    suffix: list of two strings</span>
<span class="sd">      suffix to append the columns of left and right in order to create</span>
<span class="sd">      unique names after the join</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; df1 = spark.createDataFrame([</span>
<span class="sd">        (1, &quot;jordan&quot;, &#39;DS&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;DS&#39;),</span>
<span class="sd">        (1, &quot;jack&quot;, &#39;SDE&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;SDE&#39;),</span>
<span class="sd">        (1, &quot;jack&quot;, &#39;PM&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;PM&#39;)</span>
<span class="sd">        ],        </span>
<span class="sd">        (&quot;id&quot;, &quot;name&quot;, &quot;dept&quot;)</span>
<span class="sd">    )</span>

<span class="sd">    &gt;&gt;&gt; df2 = spark.createDataFrame([</span>
<span class="sd">        (2, &quot;SDE&quot;, 20), </span>
<span class="sd">        (1, &quot;SDE&quot;, 10),</span>
<span class="sd">        (2, &quot;PM&quot;, 30),</span>
<span class="sd">        (2, &quot;BA&quot;, 40),</span>
<span class="sd">        ],</span>
<span class="sd">      (&quot;id&quot;, &quot;dept&quot;, &quot;age&quot;)</span>
<span class="sd">    )</span>

<span class="sd">    &gt;&gt;&gt; df1.ts.right_join(df2, on = [&quot;id&quot;, &quot;dept&quot;]).show()</span>
<span class="sd">    +---+----+----+---+</span>
<span class="sd">    | id|dept|name|age|</span>
<span class="sd">    +---+----+----+---+</span>
<span class="sd">    |  2| SDE|jack| 10|</span>
<span class="sd">    |  1| SDE|jack| 20|</span>
<span class="sd">    |  2|  PM|jack| 30|</span>
<span class="sd">    |  2|  BA|null| 40|</span>
<span class="sd">    +---+----+----+---+</span>

<span class="sd">    &gt;&gt;&gt; (df1.ts.right_join(df2, sql_on = &#39;(LHS.id == RHS.id) &amp; </span>
<span class="sd">    &gt;&gt;&gt;                    (LHS.dept == RHS.dept) &amp; (RHS.age &lt; 30)&#39;).show())</span>
<span class="sd">    +----+----+----+----+------+---+</span>
<span class="sd">    |  id|name|dept|id_y|dept_y|age|</span>
<span class="sd">    +----+----+----+----+------+---+</span>
<span class="sd">    |   2|jack| SDE|   2|   SDE| 10|</span>
<span class="sd">    |   1|jack| SDE|   1|   SDE| 20|</span>
<span class="sd">    |null|null|null|   2|    PM| 30|</span>
<span class="sd">    |null|null|null|   2|    BA| 40|</span>
<span class="sd">    +----+----+----+----+------+---+</span>

<span class="sd">    &gt;&gt;&gt; df1.ts.right_join(df2, on_x = [&#39;id&#39;, &#39;dept&#39;], on_y = [&#39;age&#39;, &#39;dept&#39;]).show()</span>
<span class="sd">    # +----+----+----+----+------+---+</span>
<span class="sd">    # |  id|name|dept|id_y|dept_y|age|</span>
<span class="sd">    # +----+----+----+----+------+---+</span>
<span class="sd">    # |null|null|null|   2|   SDE| 10|</span>
<span class="sd">    # |null|null|null|   1|   SDE| 20|</span>
<span class="sd">    # |null|null|null|   2|    PM| 30|</span>
<span class="sd">    # |null|null|null|   2|    BA| 40|</span>
<span class="sd">    # +----+----+----+----+------+---+</span>

<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pyspark_df</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">on_x</span><span class="p">,</span> <span class="n">on_y</span><span class="p">,</span> <span class="n">sql_on</span><span class="p">,</span> <span class="n">suffix</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">)</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark.inner_join"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.inner_join">[docs]</a>  <span class="k">def</span> <span class="nf">inner_join</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                 <span class="n">pyspark_df</span><span class="p">,</span> 
                 <span class="n">on</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                 <span class="n">on_x</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                 <span class="n">on_y</span> <span class="o">=</span> <span class="kc">None</span> <span class="p">,</span> 
                 <span class="n">sql_on</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                 <span class="n">suffix</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;_y&quot;</span><span class="p">]</span>
                 <span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Joins columns of pyspark_df to self by matching rows</span>
<span class="sd">    Includes only matching keys in pyspark_df and self</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pyspark_df (pyspark.sql.DataFrame)</span>
<span class="sd">    on: string or a list of strings</span>
<span class="sd">      Common column names to match</span>
<span class="sd">    on_x: string or a list of strings</span>
<span class="sd">      Column names of self to be matched with arg &#39;on_y&#39;</span>
<span class="sd">    on_y: string or a list of strings</span>
<span class="sd">      Column names of y to be matched with arg &#39;on_x&#39;</span>
<span class="sd">    sql_on: string</span>
<span class="sd">      SQL expression used to join both DataFrames. </span>
<span class="sd">      Recommended for inequality joins.</span>
<span class="sd">      The left table has to be specified as &#39;LHS&#39; and the right table as &#39;RHS&#39;.</span>
<span class="sd">      e.g. &#39;(LHS.dept == RHS.dept) &amp; (LHS.age &gt;= RHS.age) &amp; (RHS.age &lt; 30)&#39;</span>
<span class="sd">    suffix: list of two strings</span>
<span class="sd">      suffix to append the columns of left and right in order to create</span>
<span class="sd">      unique names after the join</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; df1 = spark.createDataFrame([</span>
<span class="sd">        (1, &quot;jordan&quot;, &#39;DS&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;DS&#39;),</span>
<span class="sd">        (1, &quot;jack&quot;, &#39;SDE&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;SDE&#39;),</span>
<span class="sd">        (1, &quot;jack&quot;, &#39;PM&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;PM&#39;)</span>
<span class="sd">        ],        </span>
<span class="sd">        (&quot;id&quot;, &quot;name&quot;, &quot;dept&quot;)</span>
<span class="sd">    )</span>

<span class="sd">    &gt;&gt;&gt; df2 = spark.createDataFrame([</span>
<span class="sd">        (2, &quot;SDE&quot;, 20), </span>
<span class="sd">        (1, &quot;SDE&quot;, 10),</span>
<span class="sd">        (2, &quot;PM&quot;, 30),</span>
<span class="sd">        (2, &quot;BA&quot;, 40),</span>
<span class="sd">        ],</span>
<span class="sd">      (&quot;id&quot;, &quot;dept&quot;, &quot;age&quot;)</span>
<span class="sd">    )</span>

<span class="sd">    &gt;&gt;&gt; df1.ts.inner_join(df2, on = [&quot;id&quot;, &quot;dept&quot;]).show()</span>
<span class="sd">    +---+----+----+---+</span>
<span class="sd">    | id|dept|name|age|</span>
<span class="sd">    +---+----+----+---+</span>
<span class="sd">    |  1| SDE|jack| 20|</span>
<span class="sd">    |  2|  PM|jack| 30|</span>
<span class="sd">    |  2| SDE|jack| 10|</span>
<span class="sd">    +---+----+----+---+</span>

<span class="sd">    &gt;&gt;&gt; (df1.ts.inner_join(df2, sql_on = &#39;(LHS.id == RHS.id) &amp; </span>
<span class="sd">    &gt;&gt;&gt;                    (LHS.dept == RHS.dept) &amp; (RHS.age &lt; 30)&#39;).show())</span>
<span class="sd">    +---+----+----+----+------+---+</span>
<span class="sd">    | id|name|dept|id_y|dept_y|age|</span>
<span class="sd">    +---+----+----+----+------+---+</span>
<span class="sd">    |  1|jack| SDE|   1|   SDE| 20|</span>
<span class="sd">    |  2|jack| SDE|   2|   SDE| 10|</span>
<span class="sd">    +---+----+----+----+------+---+</span>

<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pyspark_df</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">on_x</span><span class="p">,</span> <span class="n">on_y</span><span class="p">,</span> <span class="n">sql_on</span><span class="p">,</span> <span class="n">suffix</span><span class="p">,</span> <span class="s1">&#39;inner&#39;</span><span class="p">)</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark.full_join"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.full_join">[docs]</a>  <span class="k">def</span> <span class="nf">full_join</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                <span class="n">pyspark_df</span><span class="p">,</span> 
                <span class="n">on</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                <span class="n">on_x</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                <span class="n">on_y</span> <span class="o">=</span> <span class="kc">None</span> <span class="p">,</span> 
                <span class="n">sql_on</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                <span class="n">suffix</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;_y&quot;</span><span class="p">]</span>
                <span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Joins columns of pyspark_df to self by matching rows</span>
<span class="sd">    Includes all keys from both pyspark_df and self</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pyspark_df (pyspark.sql.DataFrame)</span>
<span class="sd">    on: string or a list of strings</span>
<span class="sd">      Common column names to match</span>
<span class="sd">    on_x: string or a list of strings</span>
<span class="sd">      Column names of self to be matched with arg &#39;on_y&#39;</span>
<span class="sd">    on_y: string or a list of strings</span>
<span class="sd">      Column names of y to be matched with arg &#39;on_x&#39;</span>
<span class="sd">    sql_on: string</span>
<span class="sd">      SQL expression used to join both DataFrames. </span>
<span class="sd">      Recommended for inequality joins.</span>
<span class="sd">      The left table has to be specified as &#39;LHS&#39; and the right table as &#39;RHS&#39;.</span>
<span class="sd">      e.g. &#39;(LHS.dept == RHS.dept) &amp; (LHS.age &gt;= RHS.age) &amp; (RHS.age &lt; 30)&#39;</span>
<span class="sd">    suffix: list of two strings</span>
<span class="sd">      suffix to append the columns of left and right in order to create</span>
<span class="sd">      unique names after the join</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; df1 = spark.createDataFrame([</span>
<span class="sd">        (1, &quot;jordan&quot;, &#39;DS&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;DS&#39;),</span>
<span class="sd">        (1, &quot;jack&quot;, &#39;SDE&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;SDE&#39;),</span>
<span class="sd">        (1, &quot;jack&quot;, &#39;PM&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;PM&#39;)</span>
<span class="sd">        ],        </span>
<span class="sd">        (&quot;id&quot;, &quot;name&quot;, &quot;dept&quot;)</span>
<span class="sd">    )</span>

<span class="sd">    &gt;&gt;&gt; df2 = spark.createDataFrame([</span>
<span class="sd">        (2, &quot;SDE&quot;, 20), </span>
<span class="sd">        (1, &quot;SDE&quot;, 10),</span>
<span class="sd">        (2, &quot;PM&quot;, 30),</span>
<span class="sd">        (2, &quot;BA&quot;, 40),</span>
<span class="sd">        ],</span>
<span class="sd">      (&quot;id&quot;, &quot;dept&quot;, &quot;age&quot;)</span>
<span class="sd">    )</span>

<span class="sd">    &gt;&gt;&gt; df1.ts.full_join(df2, on = [&quot;id&quot;, &quot;dept&quot;]).show()</span>
<span class="sd">    +---+----+------+----+</span>
<span class="sd">    | id|dept|  name| age|</span>
<span class="sd">    +---+----+------+----+</span>
<span class="sd">    |  1|  DS|jordan|null|</span>
<span class="sd">    |  1|  PM|  jack|null|</span>
<span class="sd">    |  1| SDE|  jack|  20|</span>
<span class="sd">    |  2|  BA|  null|  40|</span>
<span class="sd">    |  2|  DS|  jack|null|</span>
<span class="sd">    |  2|  PM|  jack|  30|</span>
<span class="sd">    |  2| SDE|  jack|  10|</span>
<span class="sd">    +---+----+------+----+</span>

<span class="sd">    &gt;&gt;&gt; (df1.ts.full_join(df2, sql_on = &#39;(LHS.id == RHS.id) &amp; </span>
<span class="sd">    &gt;&gt;&gt;                   (LHS.dept == RHS.dept) &amp; (RHS.age &lt; 30)&#39;).show())</span>
<span class="sd">    +----+------+----+----+------+----+</span>
<span class="sd">    |  id|  name|dept|id_y|dept_y| age|</span>
<span class="sd">    +----+------+----+----+------+----+</span>
<span class="sd">    |   1|jordan|  DS|null|  null|null|</span>
<span class="sd">    |   1|  jack|  PM|null|  null|null|</span>
<span class="sd">    |   1|  jack| SDE|   1|   SDE|  20|</span>
<span class="sd">    |null|  null|null|   2|    BA|  40|</span>
<span class="sd">    |   2|  jack|  DS|null|  null|null|</span>
<span class="sd">    |   2|  jack|  PM|null|  null|null|</span>
<span class="sd">    |null|  null|null|   2|    PM|  30|</span>
<span class="sd">    |   2|  jack| SDE|   2|   SDE|  10|</span>
<span class="sd">    +----+------+----+----+------+----+</span>

<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pyspark_df</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">on_x</span><span class="p">,</span> <span class="n">on_y</span><span class="p">,</span> <span class="n">sql_on</span><span class="p">,</span> <span class="n">suffix</span><span class="p">,</span> <span class="s1">&#39;full&#39;</span><span class="p">)</span></div>
  
  <span class="c1"># alias</span>
  <span class="n">outer_join</span> <span class="o">=</span> <span class="n">full_join</span>
  
<div class="viewcode-block" id="acc_on_pyspark.anti_join"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.anti_join">[docs]</a>  <span class="k">def</span> <span class="nf">anti_join</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                <span class="n">pyspark_df</span><span class="p">,</span> 
                <span class="n">on</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                <span class="n">on_x</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                <span class="n">on_y</span> <span class="o">=</span> <span class="kc">None</span> <span class="p">,</span> 
                <span class="n">sql_on</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Joins columns of pyspark_df to self by matching rows</span>
<span class="sd">    Includes keys in self if not present in pyspark_df</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pyspark_df (pyspark.sql.DataFrame)</span>
<span class="sd">    on: string or a list of strings</span>
<span class="sd">      Common column names to match</span>
<span class="sd">    on_x: string or a list of strings</span>
<span class="sd">      Column names of self to be matched with arg &#39;on_y&#39;</span>
<span class="sd">    on_y: string or a list of strings</span>
<span class="sd">      Column names of y to be matched with arg &#39;on_x&#39;</span>
<span class="sd">    sql_on: string</span>
<span class="sd">      SQL expression used to join both DataFrames. </span>
<span class="sd">      Recommended for inequality joins.</span>
<span class="sd">      The left table has to be specified as &#39;LHS&#39; and the right table as &#39;RHS&#39;.</span>
<span class="sd">      e.g. &#39;(LHS.dept == RHS.dept) &amp; (LHS.age &gt;= RHS.age) &amp; (RHS.age &lt; 30)&#39;</span>
<span class="sd">    suffix: list of two strings</span>
<span class="sd">      suffix to append the columns of left and right in order to create</span>
<span class="sd">      unique names after the join</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    # Create the DataFrames</span>
<span class="sd">    &gt;&gt;&gt; df1 = spark.createDataFrame([</span>
<span class="sd">        (1, &quot;jordan&quot;, &#39;DS&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;DS&#39;),</span>
<span class="sd">        (1, &quot;jack&quot;, &#39;SDE&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;SDE&#39;),</span>
<span class="sd">        (1, &quot;jack&quot;, &#39;PM&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;PM&#39;)</span>
<span class="sd">        ],        </span>
<span class="sd">        (&quot;id&quot;, &quot;name&quot;, &quot;dept&quot;)</span>
<span class="sd">    )</span>

<span class="sd">    &gt;&gt;&gt; df2 = spark.createDataFrame([</span>
<span class="sd">        (2, &quot;SDE&quot;, 20), </span>
<span class="sd">        (1, &quot;SDE&quot;, 10),</span>
<span class="sd">        (2, &quot;PM&quot;, 30),</span>
<span class="sd">        (2, &quot;BA&quot;, 40),</span>
<span class="sd">        ],</span>
<span class="sd">      (&quot;id&quot;, &quot;dept&quot;, &quot;age&quot;)</span>
<span class="sd">    )</span>

<span class="sd">    &gt;&gt;&gt; df1.ts.anti_join(df2, on = [&quot;id&quot;, &quot;dept&quot;]).show()</span>
<span class="sd">    +---+----+------+</span>
<span class="sd">    | id|dept|  name|</span>
<span class="sd">    +---+----+------+</span>
<span class="sd">    |  1|  DS|jordan|</span>
<span class="sd">    |  2|  DS|  jack|</span>
<span class="sd">    |  1|  PM|  jack|</span>
<span class="sd">    +---+----+------+</span>

<span class="sd">    &gt;&gt;&gt; (df1.ts.anti_join(df2, sql_on = &#39;(LHS.id == RHS.id) &amp; </span>
<span class="sd">                          (LHS.dept == RHS.dept) &amp; (RHS.age &lt; 30)&#39;).show())</span>
<span class="sd">    +---+------+----+</span>
<span class="sd">    | id|  name|dept|</span>
<span class="sd">    +---+------+----+</span>
<span class="sd">    |  1|jordan|  DS|</span>
<span class="sd">    |  2|  jack|  DS|</span>
<span class="sd">    |  1|  jack|  PM|</span>
<span class="sd">    |  2|  jack|  PM|</span>
<span class="sd">    +---+------+----+</span>

<span class="sd">    &gt;&gt;&gt; df1.ts.anti_join(df2, on_x = [&#39;id&#39;, &#39;dept&#39;], on_y = [&#39;age&#39;, &#39;dept&#39;]).show()</span>
<span class="sd">    +---+------+----+</span>
<span class="sd">    | id|  name|dept|</span>
<span class="sd">    +---+------+----+</span>
<span class="sd">    |  1|jordan|  DS|</span>
<span class="sd">    |  2|  jack|  DS|</span>
<span class="sd">    |  1|  jack| SDE|</span>
<span class="sd">    |  2|  jack| SDE|</span>
<span class="sd">    |  1|  jack|  PM|</span>
<span class="sd">    |  2|  jack|  PM|</span>
<span class="sd">    +---+------+----+</span>
<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pyspark_df</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">on_x</span><span class="p">,</span> <span class="n">on_y</span><span class="p">,</span> <span class="n">sql_on</span><span class="p">,</span>
                     <span class="n">suffix</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;_y&quot;</span><span class="p">],</span> <span class="n">how</span> <span class="o">=</span> <span class="s1">&#39;anti&#39;</span>
                     <span class="p">)</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark.semi_join"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.semi_join">[docs]</a>  <span class="k">def</span> <span class="nf">semi_join</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                <span class="n">pyspark_df</span><span class="p">,</span> 
                <span class="n">on</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                <span class="n">on_x</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                <span class="n">on_y</span> <span class="o">=</span> <span class="kc">None</span> <span class="p">,</span> 
                <span class="n">sql_on</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Joins columns of pyspark_df to self by matching rows</span>
<span class="sd">    Includes keys in self if present in pyspark_df</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pyspark_df (pyspark.sql.DataFrame)</span>
<span class="sd">    on: string or a list of strings</span>
<span class="sd">      Common column names to match</span>
<span class="sd">    on_x: string or a list of strings</span>
<span class="sd">      Column names of self to be matched with arg &#39;on_y&#39;</span>
<span class="sd">    on_y: string or a list of strings</span>
<span class="sd">      Column names of y to be matched with arg &#39;on_x&#39;</span>
<span class="sd">    sql_on: string</span>
<span class="sd">      SQL expression used to join both DataFrames. </span>
<span class="sd">      Recommended for inequality joins.</span>
<span class="sd">      The left table has to be specified as &#39;LHS&#39; and the right table as &#39;RHS&#39;.</span>
<span class="sd">      e.g. &#39;(LHS.dept == RHS.dept) &amp; (LHS.age &gt;= RHS.age) &amp; (RHS.age &lt; 30)&#39;</span>
<span class="sd">    suffix: list of two strings</span>
<span class="sd">      suffix to append the columns of left and right in order to create</span>
<span class="sd">      unique names after the join</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    # Create the DataFrames</span>
<span class="sd">    &gt;&gt;&gt; df1 = spark.createDataFrame([</span>
<span class="sd">        (1, &quot;jordan&quot;, &#39;DS&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;DS&#39;),</span>
<span class="sd">        (1, &quot;jack&quot;, &#39;SDE&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;SDE&#39;),</span>
<span class="sd">        (1, &quot;jack&quot;, &#39;PM&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;PM&#39;)</span>
<span class="sd">        ],        </span>
<span class="sd">        (&quot;id&quot;, &quot;name&quot;, &quot;dept&quot;)</span>
<span class="sd">    )</span>

<span class="sd">    &gt;&gt;&gt; df2 = spark.createDataFrame([</span>
<span class="sd">        (2, &quot;SDE&quot;, 20), </span>
<span class="sd">        (1, &quot;SDE&quot;, 10),</span>
<span class="sd">        (2, &quot;PM&quot;, 30),</span>
<span class="sd">        (2, &quot;BA&quot;, 40),</span>
<span class="sd">        ],</span>
<span class="sd">      (&quot;id&quot;, &quot;dept&quot;, &quot;age&quot;)</span>
<span class="sd">    )</span>

<span class="sd">    &gt;&gt;&gt; df1.ts.semi_join(df2, on = [&quot;id&quot;, &quot;dept&quot;]).show()</span>
<span class="sd">    # +---+----+----+</span>
<span class="sd">    # | id|dept|name|</span>
<span class="sd">    # +---+----+----+</span>
<span class="sd">    # |  1| SDE|jack|</span>
<span class="sd">    # |  2|  PM|jack|</span>
<span class="sd">    # |  2| SDE|jack|</span>
<span class="sd">    # +---+----+----+</span>

<span class="sd">    &gt;&gt;&gt; (df1.ts.semi_join(df2, sql_on = &#39;(LHS.id == RHS.id) &amp; </span>
<span class="sd">                          (LHS.dept == RHS.dept) &amp; (RHS.age &lt; 30)&#39;)).show()</span>
<span class="sd">    +---+------+----+</span>
<span class="sd">    | id|  name|dept|</span>
<span class="sd">    +---+------+----+</span>
<span class="sd">    |  1|jordan|  DS|</span>
<span class="sd">    |  2|  jack|  DS|</span>
<span class="sd">    |  1|  jack|  PM|</span>
<span class="sd">    |  2|  jack|  PM|</span>
<span class="sd">    +---+------+----+</span>

<span class="sd">    &gt;&gt;&gt; df1.ts.semi_join(df2, on_x = [&#39;id&#39;, &#39;dept&#39;], on_y = [&#39;age&#39;, &#39;dept&#39;]).show()</span>
<span class="sd">    # +---+----+----+</span>
<span class="sd">    # | id|name|dept|</span>
<span class="sd">    # +---+----+----+</span>
<span class="sd">    # +---+----+----+</span>
<span class="sd">    &#39;&#39;&#39;</span>
     
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pyspark_df</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">on_x</span><span class="p">,</span> <span class="n">on_y</span><span class="p">,</span> <span class="n">sql_on</span><span class="p">,</span>
                     <span class="n">suffix</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;_y&quot;</span><span class="p">],</span> <span class="n">how</span> <span class="o">=</span> <span class="s1">&#39;semi&#39;</span>
                     <span class="p">)</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark.cross_join"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.cross_join">[docs]</a>  <span class="k">def</span> <span class="nf">cross_join</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pyspark_df</span><span class="p">,</span> <span class="n">suffix</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;_y&quot;</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Returns the cartesian product of two DataFrames.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pyspark_df (pyspark.sql.DataFrame)</span>
<span class="sd">    suffix: list of two strings</span>
<span class="sd">      suffix to append the columns of left and right in order to create</span>
<span class="sd">      unique names after the join</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    # Create the DataFrames</span>
<span class="sd">    &gt;&gt;&gt; df1 = spark.createDataFrame([</span>
<span class="sd">        (1, &quot;jordan&quot;, &#39;DS&#39;),</span>
<span class="sd">        (2, &quot;jack&quot;, &#39;PM&#39;)</span>
<span class="sd">        ],        </span>
<span class="sd">        (&quot;id&quot;, &quot;name&quot;, &quot;dept&quot;)</span>
<span class="sd">    )</span>

<span class="sd">    &gt;&gt;&gt; df2 = spark.createDataFrame([</span>
<span class="sd">        (2, &quot;SDE&quot;, 20), </span>
<span class="sd">        (1, &quot;SDE&quot;, 10),</span>
<span class="sd">        ],</span>
<span class="sd">      (&quot;id&quot;, &quot;dept&quot;, &quot;age&quot;)</span>
<span class="sd">    )</span>

<span class="sd">    &gt;&gt;&gt; df1.ts.cross_join(df2).show()</span>
<span class="sd">    +---+------+----+---+----+---+</span>
<span class="sd">    | id| name|dept|id_y|dept_y|age_y|</span>
<span class="sd">    +---+------+----+---+----+---+</span>
<span class="sd">    |  1|jordan|  DS|  2| SDE| 20| </span>
<span class="sd">    |  1|jordan|  DS|  1| SDE| 10|</span>
<span class="sd">    |  2|  jack|  PM|  2| SDE| 20|</span>
<span class="sd">    |  2|  jack|  PM|  1| SDE| 10|</span>
<span class="sd">    +---+------+----+---+----+---+</span>
<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute_cross_join</span><span class="p">(</span><span class="n">pyspark_df</span><span class="p">,</span> <span class="n">suffix</span><span class="p">)</span></div>

  <span class="c1"># count methods ------------------------------------------------------------</span>
<div class="viewcode-block" id="acc_on_pyspark.count"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.count">[docs]</a>  <span class="k">def</span> <span class="nf">count</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column_names</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;n&#39;</span><span class="p">,</span> <span class="n">wt</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    count</span>
<span class="sd">    Count unique combinations of columns</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    column_names : string or list of strings</span>
<span class="sd">      Names of columns</span>
<span class="sd">    name : string, optional</span>
<span class="sd">      Name of the count column to be created (should not be an existing</span>
<span class="sd">      name). The default is &#39;n&#39;.</span>
<span class="sd">    wt: string, optional</span>
<span class="sd">      Name of the weight column. The default is None. When None, the number of</span>
<span class="sd">      rows is counted</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    pen.ts.count([&#39;species&#39;, &#39;sex&#39;]).show()</span>
<span class="sd">    pen.ts.count(&#39;species&#39;, name = &#39;cnt&#39;).show()</span>
<span class="sd">    pen.ts.count(&#39;species&#39;, wt = &#39;body_mass_g&#39;).show()</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">cn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">column_names</span><span class="p">)</span>
    
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span>\
      <span class="s2">&quot;&#39;name&#39; should be a string&quot;</span>
    <span class="k">assert</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">column_names</span><span class="p">,</span>\
      <span class="s2">&quot;&#39;name&#39; should not be an element of &#39;column_names&#39;&quot;</span>
    
    <span class="k">if</span> <span class="n">wt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">wt</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span>\
        <span class="s2">&quot;&#39;wt&#39; should be a string&quot;</span>
      <span class="k">assert</span> <span class="p">(</span><span class="n">wt</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">wt</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cn</span><span class="p">),</span>\
        <span class="s2">&quot;&#39;wt&#39; should be an existing column name and not in &#39;column_names&#39;&quot;</span>
    
    <span class="k">if</span> <span class="n">wt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
                 <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">cn</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">lit</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
                 <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="o">*</span><span class="n">cn</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">name</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
                 <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">cn_with_wt</span> <span class="o">=</span> <span class="n">cn</span> <span class="o">+</span> <span class="p">[</span><span class="n">wt</span><span class="p">]</span>
      <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
                 <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">cn_with_wt</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="o">*</span><span class="n">cn</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">wt</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
                 <span class="p">)</span>
      
    <span class="k">return</span> <span class="n">res</span></div>

<div class="viewcode-block" id="acc_on_pyspark.add_count"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.add_count">[docs]</a>  <span class="k">def</span> <span class="nf">add_count</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column_names</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;n&#39;</span><span class="p">,</span> <span class="n">wt</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    add_count</span>
<span class="sd">    Add a column of counts of unique combinations of columns</span>
<span class="sd">  </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    column_names : string or list of strings</span>
<span class="sd">      Names of columns</span>
<span class="sd">    name : string, optional</span>
<span class="sd">      Name of the count column to be created (should not be an existing</span>
<span class="sd">      name). The default is &#39;n&#39;.</span>
<span class="sd">    wt: string, optional</span>
<span class="sd">      Name of the weight column. The default is None. When None, the number of</span>
<span class="sd">      rows is counted</span>
<span class="sd">      </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.add_count([&#39;species&#39;, &#39;sex&#39;]).show()</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.add_count(&#39;species&#39;, name = &#39;cnt&#39;).show()</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.add_count(&#39;species&#39;, wt = &#39;body_mass_g&#39;).show()</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">cn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">column_names</span><span class="p">)</span>
    
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span>\
      <span class="s2">&quot;&#39;name&#39; should be a string&quot;</span>
    <span class="k">assert</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span><span class="p">,</span>\
      <span class="s2">&quot;&#39;name&#39; should not be an existing column name&quot;</span>
    
    <span class="k">if</span> <span class="n">wt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">wt</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span>\
        <span class="s2">&quot;&#39;wt&#39; should be a string&quot;</span>
      <span class="k">assert</span> <span class="p">(</span><span class="n">wt</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">wt</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cn</span><span class="p">),</span>\
        <span class="s2">&quot;&#39;wt&#39; should be an existing column name and not in &#39;column_names&#39;&quot;</span>
    
    <span class="k">if</span> <span class="n">wt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
                 <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">cn</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">lit</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
                 <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="o">*</span><span class="n">cn</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">name</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
                 <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">cn_with_wt</span> <span class="o">=</span> <span class="n">cn</span> <span class="o">+</span> <span class="p">[</span><span class="n">wt</span><span class="p">]</span>
      <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
                 <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">cn_with_wt</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="o">*</span><span class="n">cn</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">wt</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
                 <span class="p">)</span>
    
    <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
               <span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">on</span> <span class="o">=</span> <span class="n">cn</span><span class="p">,</span> <span class="n">how</span> <span class="o">=</span> <span class="s2">&quot;left&quot;</span><span class="p">)</span>
               <span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>
  
  <span class="c1"># pipe methods -------------------------------------------------------------</span>
<div class="viewcode-block" id="acc_on_pyspark.pipe"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.pipe">[docs]</a>  <span class="k">def</span> <span class="nf">pipe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    pipe</span>
<span class="sd">    returns func(self, ...)</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    func: callable</span>
<span class="sd">      function to call</span>
<span class="sd">    *args : args</span>
<span class="sd">    **kwargs : kwargs</span>
<span class="sd">    </span>
<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    Depends on func</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="n">callable</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark.pipe_tee"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.pipe_tee">[docs]</a>  <span class="k">def</span> <span class="nf">pipe_tee</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    pipe_tee</span>
<span class="sd">    use pipe for side-effect and return input</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    func: callable</span>
<span class="sd">      function to call</span>
<span class="sd">    *args : args</span>
<span class="sd">    **kwargs : kwargs</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Input pyspark dataframe</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="n">callable</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="n">func</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="c1"># side-effect</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span></div>
  
  <span class="c1"># slice min and max methods -----------------------------------------------</span>
<div class="viewcode-block" id="acc_on_pyspark.slice_min"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.slice_min">[docs]</a>  <span class="k">def</span> <span class="nf">slice_min</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                <span class="n">n</span><span class="p">,</span>
                <span class="n">order_by_column</span><span class="p">,</span>
                <span class="n">with_ties</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
                <span class="n">by</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    slice_min</span>
<span class="sd">    Subset top rows ordered by some column</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n : int</span>
<span class="sd">      Number of rows to subset</span>
<span class="sd">    order_by_column : string</span>
<span class="sd">      Name of the column to order by in ascending nulls to last</span>
<span class="sd">    with_ties : bool, optional</span>
<span class="sd">      Whether to return all rows when ordering results in ties.</span>
<span class="sd">      The default is True.</span>
<span class="sd">    by : string or list of strings, optional</span>
<span class="sd">      column(s) to group by. The default is None.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    </span>
<span class="sd">    Details</span>
<span class="sd">    -------</span>
<span class="sd">    The ordering always keeps null to last</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.slice_min(n = 2,</span>
<span class="sd">    &gt;&gt;&gt;                  order_by_column = &#39;bill_depth_mm&#39;,</span>
<span class="sd">    &gt;&gt;&gt;                  with_ties = False,</span>
<span class="sd">    &gt;&gt;&gt;                  by = [&#39;species&#39;, &#39;sex&#39;]</span>
<span class="sd">    &gt;&gt;&gt;                  )</span>
<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span>\
      <span class="s2">&quot;n should be a positive integer&quot;</span>
    <span class="n">order_by_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_order_by</span><span class="p">((</span><span class="n">order_by_column</span><span class="p">,</span> <span class="s1">&#39;asc&#39;</span><span class="p">))</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">with_ties</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span>\
      <span class="s2">&quot;&#39;with_ties&#39; should be a bool&quot;</span>
    
    <span class="c1"># create windowspec</span>
    <span class="k">if</span> <span class="n">by</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">win</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_windowspec</span><span class="p">(</span><span class="n">order_by</span> <span class="o">=</span> <span class="n">order_by_spec</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">by</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_by</span><span class="p">(</span><span class="n">by</span><span class="p">)</span>
      <span class="n">win</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_windowspec</span><span class="p">(</span><span class="n">order_by</span> <span class="o">=</span> <span class="n">order_by_spec</span><span class="p">,</span> <span class="n">by</span> <span class="o">=</span> <span class="n">by</span><span class="p">)</span>
    
    <span class="c1"># decide on ranking function</span>
    <span class="k">if</span> <span class="n">with_ties</span><span class="p">:</span>
      <span class="n">rank_func</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dense_rank</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">rank_func</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">row_number</span><span class="p">()</span>
    
    <span class="c1"># core</span>
    <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
               <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;_rn&#39;</span><span class="p">,</span> <span class="n">rank_func</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">win</span><span class="p">))</span>
               <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s1">&#39;_rn&#39;</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">n</span><span class="p">)</span>
               <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;_rn&#39;</span><span class="p">)</span>
               <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">res</span></div>
    
<div class="viewcode-block" id="acc_on_pyspark.slice_max"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.slice_max">[docs]</a>  <span class="k">def</span> <span class="nf">slice_max</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                <span class="n">n</span><span class="p">,</span>
                <span class="n">order_by_column</span><span class="p">,</span>
                <span class="n">with_ties</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
                <span class="n">by</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    slice_max</span>
<span class="sd">    Subset top rows ordered by some column</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n : int</span>
<span class="sd">      Number of rows to subset</span>
<span class="sd">    order_by_column : string</span>
<span class="sd">      Name of the column to order by in descending nulls to first</span>
<span class="sd">    with_ties : bool, optional</span>
<span class="sd">      Whether to return all rows when ordering results in ties.</span>
<span class="sd">      The default is True.</span>
<span class="sd">    by : string or list of strings, optional</span>
<span class="sd">      column(s) to group by. The default is None.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    </span>
<span class="sd">    Details</span>
<span class="sd">    -------</span>
<span class="sd">    The ordering always keeps null to last</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.slice_max(n = 2,</span>
<span class="sd">    &gt;&gt;&gt;                  order_by_column = &#39;bill_depth_mm&#39;,</span>
<span class="sd">    &gt;&gt;&gt;                  with_ties = False,</span>
<span class="sd">    &gt;&gt;&gt;                  by = [&#39;species&#39;, &#39;sex&#39;]</span>
<span class="sd">    &gt;&gt;&gt;                  )</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span>\
      <span class="s2">&quot;n should be a positive integer&quot;</span>
    <span class="n">order_by_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_order_by</span><span class="p">((</span><span class="n">order_by_column</span><span class="p">,</span> <span class="s1">&#39;desc&#39;</span><span class="p">))</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">with_ties</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span>\
      <span class="s2">&quot;&#39;with_ties&#39; should be a bool&quot;</span>
    
    <span class="c1"># create windowspec</span>
    <span class="k">if</span> <span class="n">by</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">win</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_windowspec</span><span class="p">(</span><span class="n">order_by</span> <span class="o">=</span> <span class="n">order_by_spec</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">by</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_by</span><span class="p">(</span><span class="n">by</span><span class="p">)</span>
      <span class="n">win</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_windowspec</span><span class="p">(</span><span class="n">order_by</span> <span class="o">=</span> <span class="n">order_by_spec</span><span class="p">,</span> <span class="n">by</span> <span class="o">=</span> <span class="n">by</span><span class="p">)</span>
    
    <span class="c1"># decide on ranking function</span>
    <span class="k">if</span> <span class="n">with_ties</span><span class="p">:</span>
      <span class="n">rank_func</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dense_rank</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">rank_func</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">row_number</span><span class="p">()</span>
    
    <span class="c1"># core</span>
    <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
               <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;_rn&#39;</span><span class="p">,</span> <span class="n">rank_func</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">win</span><span class="p">))</span>
               <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s1">&#39;_rn&#39;</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">n</span><span class="p">)</span>
               <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;_rn&#39;</span><span class="p">)</span>
               <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">res</span></div>

  <span class="c1"># rbind --------------------------------------------------------------------</span>
<div class="viewcode-block" id="acc_on_pyspark.rbind"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.rbind">[docs]</a>  <span class="k">def</span> <span class="nf">rbind</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pyspark_df</span><span class="p">,</span> <span class="nb">id</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    rbind</span>
<span class="sd">    bind or concatenate rows of two dataframes</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pyspark_df : pyspark dataframe</span>
<span class="sd">    id : str, optional</span>
<span class="sd">      When not None, a id column created with value &#39;left&#39; for self and</span>
<span class="sd">      &#39;right&#39; for the pyspark_df.</span>
<span class="sd">      The default is None.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; df1 = pen.select([&#39;species&#39;, &#39;island&#39;, &#39;bill_length_mm&#39;])</span>
<span class="sd">    &gt;&gt;&gt; df2 = pen.select([&#39;species&#39;, &#39;island&#39;, &#39;bill_depth_mm&#39;])</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; df1.ts.rbind(df2).show()</span>
<span class="sd">    &gt;&gt;&gt; df1.ts.rbind(df2, id = &quot;id&quot;).show()</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pyspark_df</span><span class="p">,</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">dataframe</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">),</span>\
      <span class="s2">&quot;&#39;pyspark_df&#39; should be a pyspark dataframe&quot;</span>
    
    <span class="n">LHS</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
    <span class="n">RHS</span> <span class="o">=</span> <span class="n">pyspark_df</span>
    
    <span class="k">if</span> <span class="nb">id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">id</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
      <span class="n">cn</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">LHS</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">RHS</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>
      <span class="k">assert</span> <span class="nb">id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cn</span><span class="p">,</span>\
        <span class="s2">&quot;id should not be a column name of one of the two dataframes&quot;</span>
      <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="n">LHS</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="nb">id</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">lit</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">))</span>
                <span class="o">.</span><span class="n">unionByName</span><span class="p">(</span><span class="n">RHS</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="nb">id</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">lit</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">)),</span>
                             <span class="n">allowMissingColumns</span> <span class="o">=</span> <span class="kc">True</span>
                             <span class="p">)</span>
                <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">res</span> <span class="o">=</span> <span class="n">LHS</span><span class="o">.</span><span class="n">unionByName</span><span class="p">(</span><span class="n">RHS</span><span class="p">,</span> <span class="n">allowMissingColumns</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="nb">id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">non_id_cols</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">([</span><span class="nb">id</span><span class="p">]))</span>
      <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">select</span><span class="p">([</span><span class="nb">id</span><span class="p">]</span> <span class="o">+</span> <span class="n">non_id_cols</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">res</span></div>
  
  <span class="c1"># alias</span>
  <span class="n">bind_rows</span> <span class="o">=</span> <span class="n">rbind</span>
  
  <span class="c1"># union --------------------------------------------------------------------</span>
<div class="viewcode-block" id="acc_on_pyspark.union"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.union">[docs]</a>  <span class="k">def</span> <span class="nf">union</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pyspark_df</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    rbind</span>
<span class="sd">    bind or concatenate rows of two dataframes</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pyspark_df : pyspark dataframe</span>
<span class="sd">    id : str, optional</span>
<span class="sd">      When not None, a id column created with value &#39;left&#39; for self and</span>
<span class="sd">      &#39;right&#39; for the pyspark_df.</span>
<span class="sd">      The default is None.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; df1 = pen.ts.slice_max(n = 2,</span>
<span class="sd">    &gt;&gt;&gt;                        order_by_column = &#39;bill_length_mm&#39;,</span>
<span class="sd">    &gt;&gt;&gt;                        with_ties = False</span>
<span class="sd">    &gt;&gt;&gt;                        )</span>
<span class="sd">    &gt;&gt;&gt; df2 = pen.ts.slice_max(n = 4,</span>
<span class="sd">    &gt;&gt;&gt;                        order_by_column = &#39;bill_length_mm&#39;,</span>
<span class="sd">    &gt;&gt;&gt;                        with_ties = False</span>
<span class="sd">    &gt;&gt;&gt;                        )</span>
<span class="sd">    &gt;&gt;&gt; </span>
<span class="sd">    &gt;&gt;&gt; df1.ts.union(df2).show()</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pyspark_df</span><span class="p">,</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">dataframe</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">),</span>\
      <span class="s2">&quot;&#39;pyspark_df&#39; should be a pyspark dataframe&quot;</span>
    
    <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
               <span class="o">.</span><span class="n">unionByName</span><span class="p">(</span><span class="n">pyspark_df</span><span class="p">,</span> <span class="n">allowMissingColumns</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
               <span class="o">.</span><span class="n">distinct</span><span class="p">()</span>
               <span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>
  
  <span class="c1"># pivot methods ------------------------------------------------------------</span>
<div class="viewcode-block" id="acc_on_pyspark.pivot_wider"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.pivot_wider">[docs]</a>  <span class="k">def</span> <span class="nf">pivot_wider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                  <span class="n">names_from</span><span class="p">,</span>
                  <span class="n">values_from</span><span class="p">,</span>
                  <span class="n">values_fill</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                  <span class="n">values_fn</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                  <span class="n">id_cols</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                  <span class="n">sep</span> <span class="o">=</span> <span class="s2">&quot;__&quot;</span><span class="p">,</span>
                  <span class="n">names_prefix</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
                  <span class="n">names_expand</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                  <span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Pivot data from long to wide</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    names_from: string or list of strings</span>
<span class="sd">      column names whose unique combinations are expected to become column</span>
<span class="sd">      new names in the result</span>
<span class="sd">    values_from: string or list of strings</span>
<span class="sd">      column names to fill the new columns with</span>
<span class="sd">    values_fill: scalar, list or dict (default is None)</span>
<span class="sd">      Optionally, a (scalar) value that specifies what each value should be</span>
<span class="sd">      filled in with when missing.</span>
<span class="sd">      This can be a dictionary if you want to apply different fill values to</span>
<span class="sd">      different value columns.</span>
<span class="sd">      Make sure only compatible data types are used in conjunction with </span>
<span class="sd">      the pyspark column.</span>
<span class="sd">      Missing values can only be filled with a scalar, or empty python</span>
<span class="sd">      list value.</span>
<span class="sd">    </span>
<span class="sd">    values_fn: string(of pyspark functions) or </span>
<span class="sd">               a dict of strings(of pyspark funtions) (default is None)</span>
<span class="sd">      A function to handle multiple values per row in the result.</span>
<span class="sd">      When a dict, keys should be a subset of arg &#39;values_from&#39;.</span>
<span class="sd">      F.collect_list is applied by default in case nothing is specified.</span>
<span class="sd">      The string pf pyspark functions should be passed as a string </span>
<span class="sd">      starting with &#39;F.&#39;</span>
<span class="sd">      This is to indicate that the function is from pyspark.</span>
<span class="sd">      Unlist the pivot columns to scalar values if and only if:</span>
<span class="sd">      1. values_fn is None and values_fn is None</span>
<span class="sd">      2. all the pivot columns are of type list/array and all the pivot_cols</span>
<span class="sd">         have values with a maximum length of 1.</span>
<span class="sd">    </span>
<span class="sd">    id_cols: string or list of strings, default is None</span>
<span class="sd">      Names of the columns that should uniquely identify an observation </span>
<span class="sd">      (row) after widening (columns of the original dataframe that are</span>
<span class="sd">      supposed to stay put)</span>
<span class="sd">        </span>
<span class="sd">    sep: string (default is &quot;__&quot;)</span>
<span class="sd">      seperator to use while creating resulting column names</span>
<span class="sd">        </span>
<span class="sd">    names_prefix: string (default is &quot;&quot;)</span>
<span class="sd">      prefix for new columns</span>

<span class="sd">    names_expand: boolean (default is False)</span>
<span class="sd">      When True, he output will contain column names corresponding </span>
<span class="sd">      to a complete expansion of all possible values in names_from. </span>
<span class="sd">      Implicit factor levels that aren&#39;t represented in the data will</span>
<span class="sd">      become explicit. </span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.pivot_wider(id_cols = &quot;island&quot;,</span>
<span class="sd">    &gt;&gt;&gt;                    names_from  = &quot;sex,</span>
<span class="sd">    &gt;&gt;&gt;                    values_from = &quot;bill_length_mm&quot;</span>
<span class="sd">    &gt;&gt;&gt;                   )</span>
<span class="sd">    &gt;&gt;&gt; # All three inputs: &#39;id_cols&#39;, &#39;names_from&#39;, &#39;values_from&#39; can be lists</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.pivot_wider(id_cols = [&quot;island&quot;, &quot;sex&quot;], </span>
<span class="sd">    &gt;&gt;&gt;                   names_from  = &quot;species&quot;,</span>
<span class="sd">    &gt;&gt;&gt;                   values_from = &quot;bill_length_mm&quot;</span>
<span class="sd">    &gt;&gt;&gt;                   )</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.pivot_wider(</span>
<span class="sd">    &gt;&gt;&gt;     id_cols       = [&quot;island&quot;, &quot;sex&quot;]</span>
<span class="sd">    &gt;&gt;&gt;     , names_from  = &quot;species&quot;</span>
<span class="sd">    &gt;&gt;&gt;     , values_from = [&quot;bill_length_mm&quot;, &quot;bill_depth_mm&quot;]</span>
<span class="sd">    &gt;&gt;&gt;     )</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.pivot_wider(id_cols = [&quot;island&quot;, &quot;sex&quot;]</span>
<span class="sd">    &gt;&gt;&gt;                           , names_from  = [&quot;species&quot;, &quot;year&quot;]</span>
<span class="sd">    &gt;&gt;&gt;                           , values_from = &quot;bill_length_mm&quot;</span>
<span class="sd">    &gt;&gt;&gt;                           )</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.pivot_wider(</span>
<span class="sd">    &gt;&gt;&gt;     id_cols       = [&quot;island&quot;, &quot;sex&quot;]</span>
<span class="sd">    &gt;&gt;&gt;     , names_from  = [&quot;species&quot;, &quot;year&quot;]</span>
<span class="sd">    &gt;&gt;&gt;     , values_from = [&quot;bill_length_mm&quot;, &quot;bill_depth_mm&quot;]</span>
<span class="sd">    &gt;&gt;&gt;     )</span>
<span class="sd">    &gt;&gt;&gt; # when id_cols is empty, all columns except the columns from</span>
<span class="sd">    &gt;&gt;&gt; # `names_from` and `values_from` are considered as id_cols</span>
<span class="sd">    &gt;&gt;&gt; (pen.ts.select([&#39;flipper_length_mm&#39;, &#39;body_mass_g&#39;], include = False)</span>
<span class="sd">    &gt;&gt;&gt;         .pivot_wider(names_from    = [&quot;species&quot;, &quot;year&quot;]</span>
<span class="sd">    &gt;&gt;&gt;               , values_from = [&quot;bill_length_mm&quot;, &quot;bill_depth_mm&quot;]</span>
<span class="sd">    &gt;&gt;&gt;               )</span>
<span class="sd">    &gt;&gt;&gt;  )</span>
<span class="sd">    &gt;&gt;&gt; # use some prefix for new columns</span>
<span class="sd">    &gt;&gt;&gt; pen.ts.pivot_wider(id_cols       = &quot;island&quot;</span>
<span class="sd">    &gt;&gt;&gt;                           , names_from  = &quot;sex&quot;</span>
<span class="sd">    &gt;&gt;&gt;                           , values_from = &quot;bill_length_mm&quot;</span>
<span class="sd">    &gt;&gt;&gt;                           , names_prefix = &quot;gender_&quot;</span>
<span class="sd">    &gt;&gt;&gt;                           )</span>
<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="n">cn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span>
    
    <span class="n">names_from</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">names_from</span><span class="p">)</span>
    <span class="n">values_from</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">values_from</span><span class="p">)</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">values_from</span><span class="p">)</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">names_from</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>\
      <span class="p">(</span><span class="s2">&quot;arg &#39;names_from&#39; and &#39;values_from&#39; should not &quot;</span>
       <span class="s2">&quot;have common column names&quot;</span>
       <span class="p">)</span>
    <span class="n">names_values_from</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">values_from</span><span class="p">)</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">names_from</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">id_cols</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">id_cols</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">cn</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">names_values_from</span><span class="p">))</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">id_cols</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
          <span class="p">(</span><span class="s2">&quot;&#39;id_cols&#39; is turning out to be empty. Choose the &quot;</span>
           <span class="s2">&quot;&#39;names_from&#39; and &#39;values_from&#39; appropriately or specify &quot;</span>
           <span class="s2">&quot;&#39;id_cols&#39; explicitly.&quot;</span>
           <span class="p">))</span>
      <span class="k">else</span><span class="p">:</span>
          <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&#39;id_cols&#39; chosen: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">id_cols</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">id_cols</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">id_cols</span><span class="p">)</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">id_cols</span><span class="p">)</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">names_values_from</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>\
        <span class="p">(</span><span class="s2">&quot;arg &#39;id_cols&#39; should not have common names with either &quot;</span>
         <span class="s2">&quot;&#39;names_from&#39; or &#39;values_from&#39;&quot;</span>
         <span class="p">)</span>
        
    <span class="k">assert</span> <span class="p">(</span><span class="n">values_fn</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values_fn</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
            <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values_fn</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="p">),</span>\
      <span class="s2">&quot;arg &#39;values_fn&#39; should be a string or a dictionary of strings.&quot;</span>
    
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values_fn</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
      <span class="k">assert</span> <span class="n">values_fn</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;F.&#39;</span><span class="p">),</span>\
        <span class="p">(</span><span class="s2">&quot;arg &#39;values_fn&#39; should be a string starting with &#39;F.&#39;. &quot;</span>
         <span class="s2">&quot; It indicates a pyspark function.&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values_fn</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
      <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">values_fn</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">values_from</span><span class="p">)),</span>\
        <span class="p">(</span><span class="s2">&quot;arg &#39;values_fn&#39; should be a dictionary with keys as a subset &quot;</span>
         <span class="s2">&quot;of &#39;values_from&#39;&quot;</span><span class="p">)</span>
      <span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><span class="n">fn</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;F.&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">values_fn</span><span class="o">.</span><span class="n">values</span><span class="p">()]),</span>\
        <span class="p">(</span><span class="s2">&quot;arg &#39;values_fn&#39; should be a dictionary of strings starting with &quot;</span>
         <span class="s2">&quot;&#39;F.&#39; It indicates a pyspark function.&quot;</span><span class="p">)</span>
      
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values_fill</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
      <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">values_fill</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">values_from</span><span class="p">)),</span>\
        <span class="p">(</span><span class="s2">&quot;arg &#39;values_fill&#39; should be a dictionary with keys as a subset &quot;</span>
         <span class="s2">&quot;of &#39;values_from&#39;&quot;</span><span class="p">)</span>
    
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sep</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span>\
      <span class="s2">&quot;arg &#39;sep&#39; should be a string&quot;</span>
        
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">names_prefix</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span>\
      <span class="s2">&quot;arg &#39;names_prefix&#39; should be a string without spaces&quot;</span>
    <span class="k">assert</span> <span class="s1">&#39; &#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">names_prefix</span><span class="p">,</span>\
      <span class="s2">&quot;arg &#39;names_prefix&#39; should be a string without spaces&quot;</span>
    
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">names_expand</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span>\
      <span class="s2">&quot;arg &#39;names_expand&#39; should be a boolean&quot;</span>
    
    <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span>

    <span class="c1"># Construct the pyspark expression for the pivot_col via names_from</span>
    <span class="c1"># e.g. [Column&lt;&#39;name&#39;&gt;, Column&lt;&#39;name2&#39;&gt;] for names_from = [&#39;name&#39;, &#39;name2&#39;]</span>
    <span class="n">names_from_pyspark_expr</span> <span class="o">=</span> <span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names_from</span><span class="p">]</span>

    <span class="c1"># Create the pivot column in the dataframe via names_from_pyspark_expr</span>
    <span class="c1"># e.g Column&lt;&#39;name__name2&#39;&gt; for names_from = [&#39;name&#39;, &#39;name2&#39;],</span>
    <span class="c1"># where sep = &#39;__&#39;</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s1">&#39;pivot_col&#39;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">concat_ws</span><span class="p">(</span><span class="n">sep</span><span class="p">,</span> <span class="o">*</span><span class="n">names_from_pyspark_expr</span><span class="p">))</span>

    <span class="c1"># Construct the pivot columns via names_from and names_from_pyspark_expr</span>
    <span class="c1"># When names_expand = True, it will return all possible combinations of</span>
    <span class="c1"># values in names_from</span>
    <span class="c1"># When names_expand = False, it will return the unique values in names_from</span>
    <span class="n">pivot_cols</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_pivot_columns</span><span class="p">(</span><span class="n">names_from</span><span class="p">,</span> <span class="n">sep</span><span class="p">,</span> <span class="n">names_expand</span><span class="p">,</span>
                                         <span class="n">df</span><span class="p">,</span> <span class="n">names_from_pyspark_expr</span>
                                         <span class="p">)</span>

    <span class="c1"># Construct the pyspark expression for the values_from.</span>
    <span class="c1"># e.g. [Column&lt;&#39;avg(dept) AS dept&#39;&gt;,</span>
    <span class="c1"># Column&lt;&#39;collect_list(dept2) AS dept2&#39;&gt;] </span>
    <span class="c1"># for values_from = [&#39;dept&#39;, &#39;dept2&#39;] and </span>
    <span class="c1">#     values_fn = {&#39;dept&#39;: &#39;avg&#39;, &#39;dept2&#39;: &#39;collect_list&#39;}</span>
    <span class="n">values_from_pyspark_expr</span> <span class="o">=</span> <span class="p">(</span> 
      <span class="bp">self</span><span class="o">.</span><span class="n">_construct_pyspark_expr_from_values_from</span><span class="p">(</span><span class="n">values_from</span><span class="p">,</span> <span class="n">values_fn</span><span class="p">))</span>

    <span class="c1"># Core logic for pivot_wider</span>
    <span class="n">df</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="n">id_cols</span><span class="p">)</span>
            <span class="o">.</span><span class="n">pivot</span><span class="p">(</span><span class="s1">&#39;pivot_col&#39;</span><span class="p">,</span> <span class="n">pivot_cols</span><span class="p">)</span>
            <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="o">*</span><span class="n">values_from_pyspark_expr</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="c1"># Get the new pivot columns</span>
    <span class="n">new_pivot_cols</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">id_cols</span><span class="p">))</span>

    <span class="c1"># Fill missing values in the pivot columns.</span>
    <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fill_missing_values_for_pivot_columns</span><span class="p">(</span><span class="n">values_fill</span><span class="p">,</span>
                                                     <span class="n">df</span><span class="p">,</span>
                                                     <span class="n">new_pivot_cols</span>
                                                     <span class="p">)</span>

    <span class="c1"># Unlist the pivot columns to scalar values if and only if:</span>
    <span class="c1"># 1. values_fn is None and values_fn is None</span>
    <span class="c1"># 2. all the pivot columns are of type list/array and all the pivot_cols</span>
    <span class="c1">#    have values with a maximum length of 1.</span>
    <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unlist_pivot_cols</span><span class="p">(</span><span class="n">values_fill</span><span class="p">,</span> <span class="n">values_fn</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">new_pivot_cols</span><span class="p">)</span>    

    <span class="c1"># Replace empty lists or sets with None</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">new_pivot_cols</span><span class="p">:</span>
      <span class="n">col_dtype</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">col</span><span class="p">)</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">col_dtype</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;array&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">col_dtype</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;map&#39;</span><span class="p">):</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">col</span><span class="p">,</span>
                           <span class="n">F</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">col</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span>
                                  <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">col</span><span class="p">)</span>
                                  <span class="p">)</span><span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                           <span class="p">)</span>

    <span class="c1"># Rename the pivot columns in case names_prefix is passed explicitly.</span>
    <span class="k">if</span> <span class="n">names_prefix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span>  <span class="n">names_prefix</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
      <span class="n">select_expr</span> <span class="o">=</span> <span class="p">([</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">col</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">names_prefix</span> <span class="o">+</span> <span class="n">sep</span> <span class="o">+</span> <span class="n">col</span><span class="p">)</span> 
                      <span class="k">if</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">new_pivot_cols</span>
                      <span class="k">else</span> <span class="n">col</span> 
                      <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span>
                      <span class="p">])</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">select_expr</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span></div>

<div class="viewcode-block" id="acc_on_pyspark.pivot_longer"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.pivot_longer">[docs]</a>  <span class="k">def</span> <span class="nf">pivot_longer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                  <span class="n">cols</span><span class="p">,</span>
                  <span class="n">names_to</span> <span class="o">=</span> <span class="s2">&quot;name&quot;</span><span class="p">,</span>
                  <span class="n">values_to</span> <span class="o">=</span> <span class="s2">&quot;value&quot;</span><span class="p">,</span>
                  <span class="n">include</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                  <span class="n">values_drop_na</span> <span class="o">=</span> <span class="kc">False</span>
                  <span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Pivot from wide to long</span>
<span class="sd">    aka melt</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    cols: list of strings</span>
<span class="sd">      Column names to be melted.</span>
<span class="sd">      The dtypes of the columns should match.</span>
<span class="sd">      Leftover columns are considered as &#39;id&#39; columns.</span>
<span class="sd">      When include is False, &#39;cols&#39; refers to leftover columns.</span>
<span class="sd">    names_to: string (default: &#39;name&#39;)</span>
<span class="sd">      Name of the resulting column which will hold the names of the columns</span>
<span class="sd">      to be melted</span>
<span class="sd">    values_to: string (default: &#39;value&#39;)</span>
<span class="sd">      Name of the resulting column which will hold the values of the columns</span>
<span class="sd">      to be melted</span>
<span class="sd">    include: bool (default: True)</span>
<span class="sd">      If True, cols are used to melt. Else, cols are considered as &#39;id&#39;</span>
<span class="sd">      columns and the leftover columns are melted.</span>
<span class="sd">    values_drop_na: bool (default: False)</span>
<span class="sd">      Whether to drop the rows corresponding to missing value in the result</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; df = (pen.ts.select([&#39;species&#39;, </span>
<span class="sd">    &gt;&gt;&gt;                     &#39;bill_length_mm&#39;, </span>
<span class="sd">    &gt;&gt;&gt;                     &#39;bill_depth_mm&#39;, </span>
<span class="sd">    &gt;&gt;&gt;                     &#39;flipper_length_mm&#39;]</span>
<span class="sd">    &gt;&gt;&gt;                     )</span>
<span class="sd">    &gt;&gt;&gt;       )</span>
<span class="sd">    &gt;&gt;&gt; df.pivot_longer(cols = [&#39;bill_length_mm&#39;, </span>
<span class="sd">    &gt;&gt;&gt;                         &#39;bill_depth_mm&#39;,</span>
<span class="sd">    &gt;&gt;&gt;                         &#39;flipper_length_mm&#39;]</span>
<span class="sd">    &gt;&gt;&gt;                 )</span>
<span class="sd">    &gt;&gt;&gt; # pivot by specifying &#39;id&#39; columns to obtain the same result as above</span>
<span class="sd">    &gt;&gt;&gt; # this is helpful when there are many columns to melt</span>
<span class="sd">    &gt;&gt;&gt; df.pivot_longer(cols = &#39;species&#39;,</span>
<span class="sd">    &gt;&gt;&gt;                include = False</span>
<span class="sd">    &gt;&gt;&gt;                )</span>
<span class="sd">    &gt;&gt;&gt; # If you want to drop the rows corresponding to missing value in the result,</span>
<span class="sd">    &gt;&gt;&gt; # set values_drop_na to True</span>
<span class="sd">    &gt;&gt;&gt; df.pivot_longer(cols = [&#39;bill_length_mm&#39;,</span>
<span class="sd">    &gt;&gt;&gt;                         &#39;bill_depth_mm&#39;],</span>
<span class="sd">    &gt;&gt;&gt;                 values_drop_na = True</span>
<span class="sd">    &gt;&gt;&gt;                 )            </span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># assertions</span>
    <span class="n">cn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">colnames</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">cols</span><span class="p">)</span>

    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">include</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span>\
      <span class="s2">&quot;arg &#39;include&#39; should be a bool&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">include</span><span class="p">:</span>
      <span class="n">cols</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">setlist</span><span class="p">(</span><span class="n">cn</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">cols</span><span class="p">))</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">cols</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span>\
        <span class="s2">&quot;At least one column should be selected for melt&quot;</span>
    
    <span class="n">id_vars</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">cn</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">cols</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">names_to</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span>\
      <span class="s2">&quot;arg &#39;names_to&#39; should be a string&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values_to</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span>\
      <span class="s2">&quot;arg &#39;values_to&#39; should be a string&quot;</span>
    <span class="k">assert</span> <span class="n">names_to</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">id_vars</span><span class="p">,</span>\
      <span class="s2">&quot;arg &#39;names_to&#39; should not match a id column&quot;</span>
    <span class="k">assert</span> <span class="n">values_to</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">id_vars</span><span class="p">,</span>\
      <span class="s2">&quot;arg &#39;values_to&#39; should not match a id column&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values_drop_na</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span>\
      <span class="s2">&quot;arg &#39;values_drop_na&#39; should be a bool&quot;</span>

    <span class="c1"># Bulding the pyspark expression for melt.</span>
    <span class="c1"># Sample pyspark expression: stack(3,</span>
    <span class="c1">#                                 &#39;bill_length_mm&#39;, `bill_length_mm`,</span>
    <span class="c1">#                                 &#39;bill_depth_mm&#39;, `bill_depth_mm`,</span>
    <span class="c1">#                                 &#39;flipper_length_mm&#39;, `flipper_length_mm`</span>
    <span class="c1">#                                 ) as (`name`, `value`)</span>
    
    <span class="n">melt_cols</span> <span class="o">=</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">&#39;, `</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">`&quot;</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">])</span>
    <span class="n">melt_expr</span> <span class="o">=</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;stack(</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">cols</span><span class="p">)</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">melt_cols</span><span class="si">}</span><span class="s2">) as (`</span><span class="si">{</span><span class="n">names_to</span><span class="si">}</span><span class="s2">`, &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;`</span><span class="si">{</span><span class="n">values_to</span><span class="si">}</span><span class="s2">`)&quot;</span><span class="p">)</span>
  
    <span class="c1"># Melt/ pivot_longer core logic.</span>
    <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">id_vars</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">expr</span><span class="p">(</span><span class="n">melt_expr</span><span class="p">))</span>

    <span class="c1"># Drop rows with null values in the values_to column</span>
    <span class="k">if</span> <span class="n">values_drop_na</span><span class="p">:</span>
      <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">values_to</span><span class="p">)</span><span class="o">.</span><span class="n">isNotNull</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">res</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark._construct_pyspark_expr_from_values_from"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._construct_pyspark_expr_from_values_from">[docs]</a>  <span class="k">def</span> <span class="nf">_construct_pyspark_expr_from_values_from</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values_from</span><span class="p">,</span> <span class="n">values_fn</span><span class="p">):</span>
      
    <span class="k">if</span> <span class="n">values_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      
      <span class="c1"># Since values_fn is None, we do a just a simple collect_list.</span>
      <span class="c1"># e.g. [Column&lt;&#39;collect_list(dept) AS dept&#39;&gt;,</span>
      <span class="c1">#       Column&lt;&#39;collect_list(dept2) AS dept2&#39;&gt;] </span>
      <span class="c1"># for values_from = [&#39;dept&#39;, &#39;dept2&#39;] and values_fn = None</span>
      <span class="n">values_from_pyspark_expr</span> <span class="o">=</span> <span class="p">([</span><span class="n">F</span><span class="o">.</span><span class="n">collect_list</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">vf</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">vf</span><span class="p">)</span> 
                                   <span class="k">for</span> <span class="n">vf</span> <span class="ow">in</span> <span class="n">values_from</span><span class="p">]</span>
                                  <span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values_fn</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
      
      <span class="c1"># Apply the function name passed in values_fn to each column in</span>
      <span class="c1"># values_from.</span>
      <span class="c1"># e.g [Column&lt;&#39;sum(salary) AS salary&#39;&gt;,</span>
      <span class="c1">#      Column&lt;&#39;sum(salary2) AS salary2&#39;&gt;] </span>
      <span class="c1"># for values_from = [&#39;salary&#39;, &#39;salary2&#39;] and values_fn = &#39;sum&#39;</span>
      <span class="n">values_from_pyspark_expr</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">[</span><span class="nb">eval</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">values_fn</span><span class="si">}</span><span class="s2">(F.col(&#39;</span><span class="si">{</span><span class="n">vf</span><span class="si">}</span><span class="s2">&#39;)).alias(&#39;</span><span class="si">{</span><span class="n">vf</span><span class="si">}</span><span class="s2">&#39;)&quot;</span><span class="p">)</span>
         <span class="k">for</span> <span class="n">vf</span> <span class="ow">in</span> <span class="n">values_from</span>
         <span class="p">])</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values_fn</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
      <span class="n">values_from_pyspark_expr</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">vf</span> <span class="ow">in</span> <span class="n">values_from</span><span class="p">:</span>
        <span class="c1"># If the column name is not present in the dictionary, </span>
        <span class="c1"># we do a simple collect_list.</span>
        <span class="c1"># Else, we use the function name passed in the dictionary.</span>
        <span class="c1"># e.g. [Column&lt;&#39;collect_list(dept) AS dept&#39;&gt;,</span>
        <span class="c1">#       Column&lt;&#39;sum(salary) AS salary&#39;&gt;] </span>
        <span class="c1"># for values_from = [&#39;dept&#39;, &#39;salary&#39;] and </span>
        <span class="c1">#     values_fn = {&#39;salary&#39;: &#39;sum&#39;}</span>
        <span class="n">func_expr</span> <span class="o">=</span> <span class="n">values_fn</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">vf</span><span class="p">,</span> <span class="s1">&#39;F.collect_list&#39;</span><span class="p">)</span>
        <span class="n">values_from_pyspark_expr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
          <span class="nb">eval</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">func_expr</span><span class="si">}</span><span class="s2">(F.col(&#39;</span><span class="si">{</span><span class="n">vf</span><span class="si">}</span><span class="s2">&#39;)).alias(&#39;</span><span class="si">{</span><span class="n">vf</span><span class="si">}</span><span class="s2">&#39;)&quot;</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">values_from_pyspark_expr</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark._get_pivot_columns"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._get_pivot_columns">[docs]</a>  <span class="k">def</span> <span class="nf">_get_pivot_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">names_from</span><span class="p">,</span> <span class="n">sep</span><span class="p">,</span> <span class="n">names_expand</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span>
                         <span class="n">names_from_pyspark_expr</span><span class="p">):</span>
      
    <span class="c1"># when names_expand is True, all unique combinations of names_from </span>
    <span class="c1"># columns are taken</span>
    <span class="c1"># even if they are not present in the original dataframe</span>
    <span class="k">if</span> <span class="n">names_expand</span><span class="p">:</span>
      <span class="c1"># cartesian product of names_from</span>
      <span class="n">cartesian_product_names_from_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">names_from</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">distinct</span><span class="p">()</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">names_from</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">names_from</span><span class="p">)):</span>
          <span class="n">distinct_values_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">names_from</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">distinct</span><span class="p">()</span>
          <span class="n">cartesian_product_names_from_df</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">cartesian_product_names_from_df</span><span class="o">.</span><span class="n">crossJoin</span><span class="p">(</span><span class="n">distinct_values_df</span><span class="p">)</span>
            <span class="p">)</span>
    
      <span class="c1"># Construct the pivot_col from names_from</span>
      <span class="n">cartesian_product_names_from_df</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">cartesian_product_names_from_df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span>
          <span class="s1">&#39;pivot_col&#39;</span><span class="p">,</span>
          <span class="n">F</span><span class="o">.</span><span class="n">concat_ws</span><span class="p">(</span><span class="n">sep</span><span class="p">,</span> <span class="o">*</span><span class="n">names_from_pyspark_expr</span><span class="p">)</span>
          <span class="p">)</span>
        <span class="p">)</span>

      <span class="c1"># Construct the unique combinations of names_from columns in a </span>
      <span class="c1"># python list</span>
      <span class="n">pivot_cols</span> <span class="o">=</span> <span class="p">([</span><span class="n">row</span><span class="o">.</span><span class="n">pivot_col</span> 
                     <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">cartesian_product_names_from_df</span>
                                <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;pivot_col&#39;</span><span class="p">)</span><span class="o">.</span>
                                <span class="n">collect</span><span class="p">()]</span>
      <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">pivot_cols</span> <span class="o">=</span> <span class="p">([</span><span class="n">row</span><span class="o">.</span><span class="n">pivot_col</span> 
                     <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;pivot_col&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">distinct</span><span class="p">()</span><span class="o">.</span><span class="n">collect</span><span class="p">()]</span>
      <span class="p">)</span>    
      
    <span class="k">return</span> <span class="n">pivot_cols</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark._fill_missing_values_for_pivot_columns"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._fill_missing_values_for_pivot_columns">[docs]</a>  <span class="k">def</span> <span class="nf">_fill_missing_values_for_pivot_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values_fill</span><span class="p">,</span>
                                             <span class="n">df</span><span class="p">,</span> <span class="n">new_pivot_cols</span>
                                             <span class="p">):</span>
      
    <span class="c1"># values_fill = {&#39;dept&#39;: &#39;fill&#39;, &#39;dept2&#39;: []}</span>
    <span class="c1"># Construct a dictionary to fill the null values in the pivot columns.</span>
    <span class="c1"># The dictionary will only contain scalar values.</span>
    <span class="n">new_values_fill</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">if</span> <span class="n">values_fill</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values_fill</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">values_fill</span><span class="p">:</span>
          <span class="c1"># e.g cols_ending_with_col = [&#39;jack_dept&#39;, &#39;jordan_dept&#39;]</span>
          <span class="c1"># for col = &#39;dept&#39;</span>
          <span class="n">new_cols_ending_with_pivot_col</span> <span class="o">=</span> <span class="p">([</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">new_pivot_cols</span>
                                             <span class="k">if</span> <span class="n">c</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="n">col</span><span class="p">)])</span>
          <span class="c1"># e.g new_values_fill[&#39;jack_dept&#39;] = &#39;fill&#39; for col = &#39;dept&#39;</span>
          <span class="k">for</span> <span class="n">new_col</span> <span class="ow">in</span> <span class="n">new_cols_ending_with_pivot_col</span><span class="p">:</span>
            <span class="n">missing_value_to_be_filled</span> <span class="o">=</span> <span class="n">values_fill</span><span class="p">[</span><span class="n">col</span><span class="p">]</span>
            <span class="c1"># Fill the null values in the pivot columns with the empty list.</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">missing_value_to_be_filled</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
              <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">new_col</span><span class="p">,</span>
                                <span class="n">F</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">new_col</span><span class="p">)</span><span class="o">.</span><span class="n">isNull</span><span class="p">(),</span> 
                                       <span class="n">F</span><span class="o">.</span><span class="n">array</span><span class="p">()</span>
                                       <span class="p">)</span><span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">new_col</span><span class="p">))</span>
                                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">missing_value_to_be_filled</span><span class="p">):</span>
              <span class="c1"># Add the scaler value to the dictionary.</span>
              <span class="n">new_values_fill</span><span class="p">[</span><span class="n">new_col</span><span class="p">]</span> <span class="o">=</span> <span class="n">values_fill</span><span class="p">[</span><span class="n">col</span><span class="p">]</span>              
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values_fill</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        
        <span class="c1"># Fill the null values in the pivot columns with the empty list.</span>
        <span class="k">for</span> <span class="n">new_pivot_col</span> <span class="ow">in</span> <span class="n">new_pivot_cols</span><span class="p">:</span>
          <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">new_pivot_col</span><span class="p">,</span> 
                             <span class="n">F</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">new_pivot_col</span><span class="p">)</span><span class="o">.</span><span class="n">isNull</span><span class="p">(),</span> 
                                    <span class="n">F</span><span class="o">.</span><span class="n">array</span><span class="p">()</span>
                                    <span class="p">)</span><span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">new_pivot_col</span><span class="p">))</span>
                             <span class="p">)</span>
      <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">values_fill</span><span class="p">):</span>
        <span class="n">new_values_fill</span> <span class="o">=</span> <span class="p">{</span><span class="n">col</span><span class="p">:</span> <span class="n">values_fill</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">new_pivot_cols</span><span class="p">}</span>
     
      <span class="c1"># Fill the null values in the pivot columns </span>
      <span class="c1"># with the new renamed dictinary.</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">na</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">new_values_fill</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">df</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark._unlist_pivot_cols"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._unlist_pivot_cols">[docs]</a>  <span class="k">def</span> <span class="nf">_unlist_pivot_cols</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values_fill</span><span class="p">,</span> <span class="n">values_fn</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">new_pivot_cols</span><span class="p">):</span>
      
    <span class="k">if</span> <span class="n">values_fill</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">values_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="c1"># Get the data types of the pivot columns.</span>
      <span class="n">col_dtypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">col</span><span class="p">)</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">new_pivot_cols</span><span class="p">]</span>

      <span class="c1"># If all the pivot columns are of type array, </span>
      <span class="c1"># then proceed to convert them to scalars </span>
      <span class="c1"># if subsequent conditions are met.</span>
      <span class="k">if</span> <span class="nb">all</span><span class="p">([</span><span class="n">dtype</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;array&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">dtype</span> <span class="ow">in</span> <span class="n">col_dtypes</span><span class="p">]):</span>
        <span class="c1"># Check if all the pivot columns of type array </span>
        <span class="c1"># have a maximum of only one element.</span>
        <span class="n">is_column_scalar</span> <span class="o">=</span> <span class="p">[(</span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">pivot_col</span><span class="p">)</span>
                              <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="o">~</span><span class="n">F</span><span class="o">.</span><span class="n">isnull</span><span class="p">(</span><span class="n">pivot_col</span><span class="p">))</span>
                              <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">pivot_col</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
                              <span class="o">.</span><span class="n">count</span><span class="p">()</span>
                            <span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">pivot_col</span> <span class="ow">in</span> <span class="n">new_pivot_cols</span><span class="p">]</span>
        <span class="c1"># If all the pivot columns of type array have a maximum of </span>
        <span class="c1"># only one element, unlist them.</span>
        <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">is_column_scalar</span><span class="p">):</span>
          <span class="k">for</span> <span class="n">pivot_col</span> <span class="ow">in</span> <span class="n">new_pivot_cols</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">pivot_col</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">pivot_col</span><span class="p">)</span><span class="o">.</span><span class="n">getItem</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
            
    <span class="k">return</span> <span class="n">df</span></div>
  
  <span class="c1"># nest and unnest ----------------------------------------------------------</span>
<div class="viewcode-block" id="acc_on_pyspark.nest_by"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.nest_by">[docs]</a>  <span class="k">def</span> <span class="nf">nest_by</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">by</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;data&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    nest</span>
<span class="sd">    nest a pyspark dataframe per group as an array of structs</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    by : string or list of strings, optional</span>
<span class="sd">      column(s) to group by.</span>
<span class="sd">      </span>
<span class="sd">    name : string</span>
<span class="sd">      Name of the nested column which will be created.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    res : pyspark dataframe</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">by</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_by</span><span class="p">(</span><span class="n">by</span><span class="p">)</span>
    <span class="n">other_cols_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">colnames</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">by</span><span class="p">))</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span>\
      <span class="s2">&quot;name should be a string&quot;</span>
    <span class="k">assert</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">by</span><span class="p">,</span>\
      <span class="s2">&quot;name should not be one of the &#39;by&#39; column names&quot;</span>
    
    <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
               <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">by</span><span class="p">)</span>
               <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">collect_list</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">struct</span><span class="p">(</span><span class="o">*</span><span class="n">other_cols_list</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
               <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">res</span></div>
  
  <span class="c1"># alias for nest_by</span>
  <span class="n">nest</span> <span class="o">=</span> <span class="n">nest_by</span>
  
<div class="viewcode-block" id="acc_on_pyspark.unnest_wider"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.unnest_wider">[docs]</a>  <span class="k">def</span> <span class="nf">unnest_wider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">colname</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    unnest_wider</span>
<span class="sd">    creates multiple columns from a struct column</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    colname : string</span>
<span class="sd">      Name of the column of struct type.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">colname</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">colname</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">schema</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">colname</span><span class="p">)</span><span class="o">.</span><span class="n">schema</span>
    
    <span class="c1"># is colname column a struct?</span>
    <span class="n">coltype</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">dataType</span><span class="o">.</span><span class="n">typeName</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">schema</span><span class="o">.</span><span class="n">fields</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">coltype</span> <span class="o">==</span> <span class="s1">&#39;struct&#39;</span><span class="p">,</span>\
      <span class="s2">&quot;schema of &#39;colname&#39; column should be of type struct&quot;</span>
    
    <span class="c1"># get names and types of structFields (columns within struct)</span>
    <span class="n">json_obj</span>        <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">schema</span><span class="p">[</span><span class="n">colname</span><span class="p">]</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
    <span class="n">json_obj_simple</span> <span class="o">=</span> <span class="n">json_obj</span><span class="p">[</span><span class="s1">&#39;type&#39;</span><span class="p">][</span><span class="s1">&#39;fields&#39;</span><span class="p">]</span>
    <span class="n">names_column</span>    <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">json_obj_simple</span><span class="p">]</span>
    
    <span class="c1"># are colnames within struct unique?</span>
    <span class="k">assert</span> <span class="n">_is_unique_list</span><span class="p">(</span><span class="n">names_column</span><span class="p">),</span>\
      <span class="s2">&quot;names in colname struct should not be duplicated&quot;</span>
    <span class="n">rest_columns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">colnames</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">colname</span><span class="p">))</span>
    
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">names_column</span><span class="p">)</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">rest_columns</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>\
      <span class="p">(</span><span class="s2">&quot;unnest_wider results in duplicate column names. &quot;</span>
       <span class="s2">&quot;Try renaming columns other than colname&quot;</span><span class="p">)</span>
    
    <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
              <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">colname</span> <span class="o">+</span> <span class="s1">&#39;.*&#39;</span><span class="p">)</span>
              <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">colname</span><span class="p">)</span>
              <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">res</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark.unnest_longer"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.unnest_longer">[docs]</a>  <span class="k">def</span> <span class="nf">unnest_longer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">colname</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="s2">&quot;value&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    unnest_longer</span>
<span class="sd">    creates key and value columns from a struct column</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    colname : str</span>
<span class="sd">      Name of the column of struct type.</span>
<span class="sd">    name: str</span>
<span class="sd">      Name of the resulting key column. Default is &#39;name&#39;.</span>
<span class="sd">    value: str</span>
<span class="sd">      Name of the resulting value column. Default is &#39;value&#39;.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">colname</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">colname</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">schema</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">colname</span><span class="p">)</span><span class="o">.</span><span class="n">schema</span>
    
    <span class="c1"># is colname column a struct?</span>
    <span class="n">coltype</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">dataType</span><span class="o">.</span><span class="n">typeName</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">schema</span><span class="o">.</span><span class="n">fields</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">coltype</span> <span class="o">==</span> <span class="s1">&#39;struct&#39;</span><span class="p">,</span>\
      <span class="s2">&quot;schema of colname column should be of type struct&quot;</span>
    
    <span class="c1"># get names and types of structFields (columns within struct)</span>
    <span class="n">json_obj</span>        <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">schema</span><span class="p">[</span><span class="n">colname</span><span class="p">]</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
    <span class="n">json_obj_simple</span> <span class="o">=</span> <span class="n">json_obj</span><span class="p">[</span><span class="s1">&#39;type&#39;</span><span class="p">][</span><span class="s1">&#39;fields&#39;</span><span class="p">]</span>
    <span class="n">names_column</span>    <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">json_obj_simple</span><span class="p">]</span>
    
    <span class="c1"># are colnames within struct unique?</span>
    <span class="k">assert</span> <span class="n">_is_unique_list</span><span class="p">(</span><span class="n">names_column</span><span class="p">),</span>\
      <span class="s2">&quot;names in colname struct should not be duplicated&quot;</span>
    
    <span class="c1"># name and value column should not intersect with id columns</span>
    <span class="n">other_colnames</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">colnames</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">([</span><span class="n">colname</span><span class="p">]))</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span>\
      <span class="s2">&quot;&#39;name&#39; should be a string&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span>\
      <span class="s2">&quot;&#39;value&#39; should be a string&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">([</span><span class="n">x</span> <span class="ow">in</span> <span class="n">other_colnames</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">]]),</span>\
      <span class="p">(</span><span class="s2">&quot;&#39;name&#39; and &#39;value&#39; should be different from columns &quot;</span>
       <span class="s2">&quot; other than &#39;colname&#39;&quot;</span><span class="p">)</span>
    
    <span class="c1"># rename non struct columns by prepending &#39;retain_&#39;</span>
    <span class="n">sel</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="o">+</span> <span class="s2">&quot; as &quot;</span> <span class="o">+</span> <span class="p">(</span><span class="s2">&quot;retain_&quot;</span> <span class="o">+</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">other_colnames</span><span class="p">]</span>
    <span class="n">rev_sel</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;retain_&quot;</span> <span class="o">+</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; as &quot;</span> <span class="o">+</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">other_colnames</span><span class="p">]</span>
    <span class="n">retained_colnames</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;retain_&quot;</span> <span class="o">+</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">other_colnames</span><span class="p">]</span>
    
    <span class="c1"># unpivot str</span>
    <span class="c1"># proto: &quot;stack(2, &#39;Canada&#39;, Canada, &#39;China&#39;, China) as (Country,Total)&quot;</span>
    <span class="n">col_str</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&#39;&quot;</span> <span class="o">+</span> <span class="n">x</span> <span class="o">+</span> <span class="s2">&quot;&#39;,&quot;</span> <span class="o">+</span> <span class="n">x</span> <span class="o">+</span> <span class="s2">&quot;,&quot;</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">names_column</span><span class="p">]</span>
    <span class="n">col_str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">col_str</span><span class="p">)</span>
    <span class="n">col_str</span> <span class="o">=</span> <span class="n">col_str</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">unpivot_str</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;stack(&quot;</span> 
                   <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">names_column</span><span class="p">))</span> 
                   <span class="o">+</span> <span class="s2">&quot;,&quot;</span>
                   <span class="o">+</span> <span class="n">col_str</span>
                   <span class="o">+</span> <span class="s2">&quot;) as (&quot;</span>
                   <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;, &quot;</span> <span class="o">+</span> <span class="n">value</span> <span class="o">+</span> <span class="s2">&quot;)&quot;</span>
                   <span class="p">)</span>
    
    <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
               <span class="c1"># rename id cols to start with &quot;retain_&quot;</span>
               <span class="c1"># selectExpr is required instead of select</span>
               <span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="n">sel</span> <span class="o">+</span> <span class="p">[</span><span class="n">colname</span><span class="p">])</span>
               <span class="c1"># expand struct column</span>
               <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">colname</span> <span class="o">+</span> <span class="s1">&#39;.*&#39;</span><span class="p">)</span>
               <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">colname</span><span class="p">)</span>
               <span class="c1"># unpivot or pivot longer</span>
               <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="o">*</span><span class="n">retained_colnames</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">expr</span><span class="p">(</span><span class="n">unpivot_str</span><span class="p">))</span>
               <span class="c1"># drop rows where value is null</span>
               <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s1"> is not null&#39;</span><span class="p">)</span>
               <span class="c1"># rename &quot;retain&quot; columns</span>
               <span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="n">rev_sel</span> <span class="o">+</span> <span class="p">[</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">])</span>
               <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">res</span></div>
    
  
<div class="viewcode-block" id="acc_on_pyspark.unnest"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.unnest">[docs]</a>  <span class="k">def</span> <span class="nf">unnest</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">colname</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    unnest</span>
<span class="sd">    unnests an column where each element is an array of structs</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    colname : string</span>
<span class="sd">      Name of the column of struct type.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">colname</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">colname</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">schema</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">colname</span><span class="p">)</span><span class="o">.</span><span class="n">schema</span>
    
    <span class="c1"># is colname column a array?</span>
    <span class="n">coltype</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">dataType</span><span class="o">.</span><span class="n">typeName</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">schema</span><span class="o">.</span><span class="n">fields</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">coltype</span> <span class="o">==</span> <span class="s1">&#39;array&#39;</span><span class="p">,</span>\
      <span class="s2">&quot;schema of colname column should be of type array&quot;</span>
    
    <span class="c1"># explode the array column</span>
    <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
               <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">explode_outer</span><span class="p">(</span><span class="n">colname</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;_exploded&quot;</span><span class="p">))</span>
               <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">colname</span><span class="p">)</span>
               <span class="o">.</span><span class="n">withColumnRenamed</span><span class="p">(</span><span class="s2">&quot;_exploded&quot;</span><span class="p">,</span> <span class="n">colname</span><span class="p">)</span>
               <span class="p">)</span>
    
    <span class="c1"># if array resolves into a regular column after explode, then we are done.</span>
    <span class="c1"># Else, if it is a struct, widen it</span>
    <span class="n">res_names</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">res_types</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">dataType</span><span class="o">.</span><span class="n">typeName</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">res</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">fields</span><span class="p">]</span>
    <span class="n">res_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">res_names</span><span class="p">,</span> <span class="n">res_types</span><span class="p">))</span>
    
    <span class="k">if</span> <span class="n">res_dict</span><span class="p">[</span><span class="n">colname</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;struct&quot;</span><span class="p">:</span>
      <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">colname</span> <span class="o">+</span> <span class="s1">&#39;.*&#39;</span><span class="p">)</span>
                <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">colname</span><span class="p">)</span>
                <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">res</span></div>
  
<div class="viewcode-block" id="acc_on_pyspark.fill_na"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.fill_na">[docs]</a>  <span class="k">def</span> <span class="nf">fill_na</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column_direction_dict</span><span class="p">,</span> <span class="n">order_by</span><span class="p">,</span> <span class="n">by</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    fill_na (alias: fill)</span>
<span class="sd">    fill missing values from neighboring rows</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    column_direction_dict : dict</span>
<span class="sd">      key is column. value should be one among:</span>
<span class="sd">      &quot;up&quot;, &quot;down&quot;, &quot;updown&quot;, &quot;downup&quot; </span>
<span class="sd">    order_by : string, tuple or list of tuples</span>
<span class="sd">      order_by specification</span>
<span class="sd">    by : string or list of strings, optional</span>
<span class="sd">      Names of columns to partition by. The default is None.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>

<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">column_direction_dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
    <span class="n">valid_values</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;up&quot;</span><span class="p">,</span> <span class="s2">&quot;down&quot;</span><span class="p">,</span> <span class="s2">&quot;updown&quot;</span><span class="p">,</span> <span class="s2">&quot;downup&quot;</span><span class="p">]</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">column_direction_dict</span><span class="o">.</span><span class="n">values</span><span class="p">())</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">valid_values</span><span class="p">),</span>\
      <span class="sa">f</span><span class="s2">&quot;Values of column_direction_dict should be one among </span><span class="si">{</span><span class="n">valid_values</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">column_direction_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
    
    <span class="c1"># create two windowspec depending on direction</span>
    <span class="n">order_by</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_order_by</span><span class="p">(</span><span class="n">order_by</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">by</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">win_down</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_windowspec</span><span class="p">(</span><span class="n">order_by</span> <span class="o">=</span> <span class="n">order_by</span><span class="p">,</span>
                                         <span class="n">rows_between</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
                                         <span class="p">)</span>
      <span class="n">win_up</span>   <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_windowspec</span><span class="p">(</span><span class="n">order_by</span> <span class="o">=</span> <span class="n">order_by</span><span class="p">,</span>
                                         <span class="n">rows_between</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span><span class="p">]</span>
                                         <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">by</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_by</span><span class="p">(</span><span class="n">by</span><span class="p">)</span>
      <span class="n">win_down</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_windowspec</span><span class="p">(</span><span class="n">order_by</span> <span class="o">=</span> <span class="n">order_by</span><span class="p">,</span>
                                         <span class="n">by</span> <span class="o">=</span> <span class="n">by</span><span class="p">,</span>
                                         <span class="n">rows_between</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
                                         <span class="p">)</span>
      <span class="n">win_up</span>   <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_windowspec</span><span class="p">(</span><span class="n">order_by</span> <span class="o">=</span> <span class="n">order_by</span><span class="p">,</span>
                                         <span class="n">by</span> <span class="o">=</span> <span class="n">by</span><span class="p">,</span>
                                         <span class="n">rows_between</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span><span class="p">]</span>
                                         <span class="p">)</span>
    
    <span class="c1"># first round of filling -- up or down</span>
    <span class="n">col_expr_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">col_name</span><span class="p">,</span> <span class="n">direction</span> <span class="ow">in</span> <span class="n">column_direction_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="k">if</span> <span class="n">direction</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;down&quot;</span><span class="p">,</span> <span class="s2">&quot;downup&quot;</span><span class="p">]:</span>
        <span class="n">col_expr_dict</span><span class="p">[</span><span class="n">col_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">last</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">col_name</span><span class="p">),</span>
                                          <span class="n">ignorenulls</span> <span class="o">=</span> <span class="kc">True</span>
                                          <span class="p">)</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">win_down</span><span class="p">)</span>
      <span class="k">elif</span> <span class="n">direction</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;up&quot;</span><span class="p">,</span> <span class="s2">&quot;updown&quot;</span><span class="p">]:</span>
        <span class="n">col_expr_dict</span><span class="p">[</span><span class="n">col_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">first</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">col_name</span><span class="p">),</span>
                                         <span class="n">ignorenulls</span> <span class="o">=</span> <span class="kc">True</span>
                                         <span class="p">)</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">win_up</span><span class="p">)</span>
        
    <span class="c1"># 2nd round of filling -- down&#39;up&#39; or up&#39;down&#39; (focus things in quote)</span>
    <span class="n">col_expr_dict2</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">col_name</span><span class="p">,</span> <span class="n">direction</span> <span class="ow">in</span> <span class="n">column_direction_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="k">if</span> <span class="n">direction</span> <span class="o">==</span> <span class="s2">&quot;updown&quot;</span><span class="p">:</span>
        <span class="n">col_expr_dict2</span><span class="p">[</span><span class="n">col_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">last</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">col_name</span><span class="p">),</span>
                                           <span class="n">ignorenulls</span> <span class="o">=</span> <span class="kc">True</span>
                                           <span class="p">)</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">win_down</span><span class="p">)</span>
      <span class="k">elif</span> <span class="n">direction</span> <span class="o">==</span> <span class="s2">&quot;downup&quot;</span><span class="p">:</span>
        <span class="n">col_expr_dict2</span><span class="p">[</span><span class="n">col_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">first</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">col_name</span><span class="p">),</span>
                                          <span class="n">ignorenulls</span> <span class="o">=</span> <span class="kc">True</span>
                                          <span class="p">)</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">win_up</span><span class="p">)</span>
    
    <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">withColumns</span><span class="p">(</span><span class="n">col_expr_dict</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_expr_dict2</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">withColumns</span><span class="p">(</span><span class="n">col_expr_dict2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>
  
  <span class="c1"># alias for fill_na</span>
  <span class="n">fill</span> <span class="o">=</span> <span class="n">fill_na</span>

<div class="viewcode-block" id="acc_on_pyspark.drop_na"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.drop_na">[docs]</a>  <span class="k">def</span> <span class="nf">drop_na</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
              <span class="n">column_names</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
              <span class="n">how</span> <span class="o">=</span> <span class="s2">&quot;any&quot;</span><span class="p">,</span>
              <span class="n">thresh</span> <span class="o">=</span> <span class="kc">None</span>
              <span class="p">):</span>

<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    drop_na (alias: drop)</span>
<span class="sd">    drop rows with null values</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    how : string, optional</span>
<span class="sd">      &quot;any&quot; or &quot;all&quot;. The default is &quot;any&quot;.</span>
<span class="sd">      If &#39;any&#39;, drop a row if it contains any nulls. </span>
<span class="sd">      If &#39;all&#39;, drop a row only if all its values are null.</span>

<span class="sd">    column_names : string or list of strings, optional</span>
<span class="sd">      It specifies the columns to consider for null values. </span>
<span class="sd">      If a row has null values only in the specified columns,</span>
<span class="sd">      it will be dropped.</span>

<span class="sd">    thresh : int, optional</span>
<span class="sd">      Number of non-null values required to keep a row. The default is None.</span>
<span class="sd">      This overrides how parameter.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; # create a DataFrame with null values</span>
<span class="sd">    &gt;&gt;&gt; data = [(&quot;Alice&quot;, 25, None), (&quot;Bob&quot;, None, 80), (None, 30, 90)]</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame(data, [&quot;name&quot;, &quot;age&quot;, &quot;score&quot;])</span>
<span class="sd">    &gt;&gt;&gt; # drop rows with null values</span>
<span class="sd">    &gt;&gt;&gt; df1 = df.ts.drop_na()</span>
<span class="sd">    +----+---+-----+</span>
<span class="sd">    |name|age|score|</span>
<span class="sd">    +----+---+-----+</span>
<span class="sd">    +----+---+-----+</span>
<span class="sd">    &gt;&gt;&gt; # drop rows with null values in a specific column</span>
<span class="sd">    &gt;&gt;&gt; df2 = df.ts.drop_na(column_names = [&quot;age&quot;])</span>
<span class="sd">    +-----+---+-----+</span>
<span class="sd">    | name|age|score|</span>
<span class="sd">    +-----+---+-----+</span>
<span class="sd">    |Alice| 25| null|</span>
<span class="sd">    | null| 30|   90|</span>
<span class="sd">    +-----+---+-----+</span>
<span class="sd">    &gt;&gt;&gt; # drop rows with null values if all values are null.</span>
<span class="sd">    &gt;&gt;&gt; df3 = df.ts.drop_na(how = &quot;all&quot;)</span>
<span class="sd">    +-----+----+-----+</span>
<span class="sd">    | name| age|score|</span>
<span class="sd">    +-----+----+-----+</span>
<span class="sd">    |Alice|  25| null|</span>
<span class="sd">    |  Bob|null|   80|</span>
<span class="sd">    | null|  30|   90|</span>
<span class="sd">    +-----+----+-----+</span>
<span class="sd">    &gt;&gt;&gt; # drop rows with less than 3 non-null values</span>
<span class="sd">    &gt;&gt;&gt; df4 = df.ts.drop_na(thresh=3)</span>
<span class="sd">    +----+---+-----+</span>
<span class="sd">    |name|age|score|</span>
<span class="sd">    +----+---+-----+</span>
<span class="sd">    +----+---+-----+</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="n">how</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;any&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">],</span>\
      <span class="s2">&quot;how should be one among &#39;any&#39; or &#39;all&#39;&quot;</span>
    
    <span class="k">assert</span> <span class="n">thresh</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">thresh</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span>\
      <span class="s2">&quot;thresh should be an integer if specified&quot;</span>
    
    <span class="k">if</span> <span class="n">column_names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">column_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="n">column_names</span><span class="p">)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span> <span class="o">=</span> <span class="n">column_names</span><span class="p">,</span>
                             <span class="n">how</span> <span class="o">=</span> <span class="n">how</span><span class="p">,</span>
                             <span class="n">thresh</span> <span class="o">=</span> <span class="n">thresh</span><span class="p">,</span>
                             <span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>

  <span class="c1"># alias for drop_na</span>
  <span class="n">drop</span> <span class="o">=</span> <span class="n">drop_na</span>

<div class="viewcode-block" id="acc_on_pyspark.replace_na"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark.replace_na">[docs]</a>  <span class="k">def</span> <span class="nf">replace_na</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">value</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Replace missing values with a specified value.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    value: dict or a scalar or an empty list</span>
<span class="sd">      When a dict, key should be a column name and value should be the</span>
<span class="sd">      value to replace by missing values of the column</span>
<span class="sd">      When a scalar or an empty list, </span>
<span class="sd">      missing values of all columns will be replaced with value. </span>
<span class="sd">      A scalar value could be a string, a numeric value(int, float), </span>
<span class="sd">      or a boolean value.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pyspark dataframe</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tidypyspark.tidypyspark_class as ts</span>
<span class="sd">    &gt;&gt;&gt; from tidypyspark.datasets import get_penguins_path</span>
<span class="sd">    &gt;&gt;&gt; pen = spark.read.csv(get_penguins_path(), header = True, inferSchema = True)</span>
<span class="sd">    &gt;&gt;&gt; # create a DataFrame with null values</span>
<span class="sd">    &gt;&gt;&gt; data = [(&quot;Alice&quot;, 25, None, [20, 30, 40]), </span>
<span class="sd">    &gt;&gt;&gt;         (&quot;Bob&quot;, None, 80, [10, 20, 30]), </span>
<span class="sd">    &gt;&gt;&gt;         (None, 30, 90 , None)</span>
<span class="sd">    &gt;&gt;&gt;         ]</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame(data, [&quot;name&quot;, &quot;age&quot;, &quot;score&quot;, &quot;marks&quot;])</span>
<span class="sd">    +-----+----+-----+------------+</span>
<span class="sd">    | name| age|score|       marks|</span>
<span class="sd">    +-----+----+-----+------------+</span>
<span class="sd">    |Alice|  25| null|[20, 30, 40]|</span>
<span class="sd">    |  Bob|null|   80|[10, 20, 30]|</span>
<span class="sd">    | null|  30|   90|        null|</span>
<span class="sd">    +-----+----+-----+------------+</span>
<span class="sd">    &gt;&gt;&gt; # replace null values with a dictionary of column names and values</span>
<span class="sd">    &gt;&gt;&gt; df2 = df.ts.replace_na({&quot;name&quot;: &quot;A&quot;, &quot;score&quot;: 25, &quot;marks&quot;: []})</span>
<span class="sd">    +-----+----+-----+------------+</span>
<span class="sd">    | name| age|score|       marks|</span>
<span class="sd">    +-----+----+-----+------------+</span>
<span class="sd">    |Alice|  25|   25|[20, 30, 40]|</span>
<span class="sd">    |  Bob|null|   80|[10, 20, 30]|</span>
<span class="sd">    |    A|  30|   90|          []|</span>
<span class="sd">    +-----+----+-----+------------+</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span>

    <span class="c1"># Get the datatypes of the columns in the dataframe.</span>
    <span class="n">df_dtypes</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">ts</span><span class="o">.</span><span class="n">types</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_validate_compatible_datatypes</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">df_dtypes</span><span class="p">)</span>

    <span class="c1"># If replace_value is a scalar, then fillna with it.</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">subset</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">col_name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># If the value is a list, then it should be an empty list.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
          <span class="c1"># If the value is an empty list, then replace null values </span>
          <span class="c1"># with an empty array.</span>
          <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">col_name</span><span class="p">,</span> 
                             <span class="n">F</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">col_name</span><span class="p">)</span><span class="o">.</span><span class="n">isNull</span><span class="p">(),</span> <span class="n">F</span><span class="o">.</span><span class="n">array</span><span class="p">()</span>
                                   <span class="p">)</span><span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">col_name</span><span class="p">))</span>
                             <span class="p">)</span>
        <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
          <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">subset</span> <span class="o">=</span> <span class="p">[</span><span class="n">col_name</span><span class="p">])</span>

    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> 
                           <span class="n">F</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">col</span><span class="p">)</span><span class="o">.</span><span class="n">isNull</span><span class="p">(),</span> <span class="n">F</span><span class="o">.</span><span class="n">array</span><span class="p">()</span>
                                 <span class="p">)</span><span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">col</span><span class="p">))</span>
                           <span class="p">)</span>

    <span class="k">return</span> <span class="n">df</span></div>

<div class="viewcode-block" id="acc_on_pyspark._validate_compatible_datatypes"><a class="viewcode-back" href="../../autoapi/tidypyspark/tidypyspark_class/index.html#tidypyspark.tidypyspark_class.acc_on_pyspark._validate_compatible_datatypes">[docs]</a>  <span class="k">def</span> <span class="nf">_validate_compatible_datatypes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">df_dtypes</span><span class="p">):</span>
      
    <span class="c1"># Get the compatible datatypes of python and spark.</span>
    <span class="n">datatype_dict</span> <span class="o">=</span> <span class="n">_get_compatible_datatypes_of_python_and_spark</span><span class="p">()</span>
    
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
      <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_column_names</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
    
      <span class="k">for</span> <span class="n">col_name</span><span class="p">,</span> <span class="n">col_value</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">col_dtype</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">col_value</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="k">assert</span> <span class="n">df_dtypes</span><span class="p">[</span><span class="n">col_name</span><span class="p">]</span> <span class="ow">in</span> <span class="n">datatype_dict</span><span class="p">[</span><span class="n">col_dtype</span><span class="p">],</span>\
          <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;replacement value for column &#39;</span><span class="si">{</span><span class="n">col_name</span><span class="si">}</span><span class="s2">&#39; &quot;</span> 
            <span class="sa">f</span><span class="s2">&quot;should be of type &#39;</span><span class="si">{</span><span class="n">df_dtypes</span><span class="p">[</span><span class="n">col_name</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39; &quot;</span>
          <span class="p">)</span>
      
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">col_value</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
          <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_value</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>\
        <span class="p">(</span><span class="s2">&quot;replacement value should be an empty list if a &quot;</span>
         <span class="s2">&quot;list is passed as a value&quot;</span>
        <span class="p">)</span>

    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>\
      <span class="p">(</span><span class="s2">&quot;replacement value should be an empty list &quot;</span>
       <span class="s2">&quot;if a list is passed as a value&quot;</span>
      <span class="p">)</span>

      <span class="c1"># Check if all the columns are of type array.</span>
      <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">df_dtypes</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;array&quot;</span><span class="p">,</span>\
        <span class="p">(</span><span class="s2">&quot;replacement value should be an empty list &quot;</span>
         <span class="s2">&quot;if a list is passed as a value&quot;</span>
        <span class="p">)</span>

    <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
      <span class="n">value_dtype</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span>
      <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">df_dtypes</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="ow">in</span> <span class="n">datatype_dict</span><span class="p">[</span><span class="n">value_dtype</span><span class="p">],</span>\
        <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;replacement value for column &#39;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">&#39; &quot;</span>
         <span class="sa">f</span><span class="s2">&quot;should be of type </span><span class="si">{</span><span class="n">df_dtypes</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        
    <span class="k">else</span><span class="p">:</span>
      <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;value should be a scalar, an empty list or a dictionary&quot;</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Srikanth Komala sheshachala.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>